{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Conversations gone awry, Wikipedia version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at C:\\Users\\ewais\\.convokit\\downloads\\conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "import spacy\n",
    "corpus = Corpus(filename=download('conversations-gone-awry-corpus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 8069\nNumber of Utterances: 30021\nNumber of Conversations: 4188\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Radgeek\n"
     ]
    }
   ],
   "source": [
    "utt = corpus.random_utterance()\n",
    "print(utt.speaker.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversation('id': '134588266.14633.14633', 'utterances': ['134588266.14633.14633', '134588266.14679.14633', '134588899.15511.15511', '134590586.15724.15724', '134705986.16293.16293', '134706505.17026.17026', '134735593.17628.17628', '134741187.19072.19072', '134746639.19354.19354'], 'meta': {'page_title': 'Talk:Final Fantasy XIII', 'page_id': 4920823, 'pair_id': '127102700.50633.50633', 'conversation_has_personal_attack': True, 'verified': False, 'pair_verified': False, 'annotation_year': '2019', 'split': 'test'})\n"
     ]
    }
   ],
   "source": [
    "convo = corpus.random_conversation()\n",
    "print(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['134588266.14633.14633', '134588266.14679.14633', '134588899.15511.15511', '134590586.15724.15724', '134706505.17026.17026', '134735593.17628.17628']\n['72.49.194.145', '72.49.194.145', 'Corpsedust', 'NicholaiDaedalus', '72.49.194.145', 'NicholaiDaedalus']\n['134588266.14633.14633', '134588266.14679.14633', '134588899.15511.15511', '134590586.15724.15724', '134706505.17026.17026', '134741187.19072.19072']\n['72.49.194.145', '72.49.194.145', 'Corpsedust', 'NicholaiDaedalus', '72.49.194.145', 'Bluerfn']\n"
     ]
    }
   ],
   "source": [
    "paths = convo.get_longest_paths()\n",
    "for path in paths:\n",
    "    print([utt.id for utt in path])\n",
    "    print([utt.get_speaker().id for utt in path])"
   ]
  },
  {
   "source": [
    "## Utterance features\n",
    "- **id**: index of the utterance\n",
    "- **conversation_id**: id of the first utterance in the converstaion this utterance belongs to\n",
    "- **reply-to**: index of the utterance to which this utterance replies to (None if not a reply)\n",
    "- **speaker**: the speaker who authored the utterance\n",
    "- **timestamp**: timestamp of utterance\n",
    "- **text**: textual content of the utterance\n",
    "- **meta**: metadata for each utterance\n",
    "    - **is_section_header**: whether the utterance is a conversation \"title\" or \"subject\" (if true, the utterance should be ignored)\n",
    "    - **comment_has_personal_attack**: whether this comment was judged by 3 crowdsourced annotators to contain a personal comment_has_personal_attack\n",
    "    - **parsed**: SpaCy parsed version of the utterance text\n",
    "        - **rt**: ??\n",
    "        - **toks**: List of parsed tokens\n",
    "            - **tok**: the token (word, punctuation, etc.)\n",
    "            - **tag**: Detailed part of speech tag\n",
    "            - **dep**: syntactic dependency, i.e. the relation between the tokens\n",
    "            - **up**: list related to dn, not sure how\n",
    "            - **dn**: list related to up, not sure how"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conversation features\n",
    "\n",
    "- **id**: id of the conversation\n",
    "- **utterances**: ids of utterances in the conversation (in order I presume)\n",
    "- **meta**: conversation metadata\n",
    "    - **page_title**: title of page under which conversation is occurring\n",
    "    - **page_id**: unique numerical id of the talk page\n",
    "    - **pair_id**: the id of the conversation that this comment's conversation is paired with\n",
    "    - **conversation_has_personal_attack**: whether any comment in this comment's conversation contains a personal attack\n",
    "    - **verified**: whether the personal attack label has been verified by an internal annotator\n",
    "    - **pair_verified**: whether the personal attack label has been double checked by the internal annotator\n",
    "    - **annotation_year**: self explanatory\n",
    "    - **split**: (train, test, or val) whether this conversation was used as train, test, or val in \"Trouble on the Horizon\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we want to find the conversations that are easy to analyze, i.e. have a structure like (a -> b -> a -> b -> ...). detect_interlocution should reveal those conversations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(639/4188) 15.3% conversations valid\n"
     ]
    }
   ],
   "source": [
    "# We want to consider conversations with a call-reply structure between two speakers, having at least five utterances\n",
    "def detect_interlocution(conv, min_utts, print=False):\n",
    "    '''\n",
    "    Finds whether the conversation has a call-reply structure between two speakers with at least min_utts utterances\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "        > min_utts - the minimum number of utterances that constitute a valid conversation\n",
    "        > print - whether or not to print why the conversation was rejected\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > bool representing whether or not the conversation's longest path has the aforementioned structure\n",
    "    '''\n",
    "    # At the moment, only considering first longest path if there are multiple # TODO: Add functionality to examine all paths\n",
    "    try:\n",
    "        longest_path = conv.get_longest_paths()[0]\n",
    "    except ValueError as v:\n",
    "        if print:\n",
    "            print(v)\n",
    "            print('skipping...')\n",
    "        return False\n",
    "    \n",
    "    if len(longest_path) < min_utts:\n",
    "        if print:\n",
    "            print('Less than {} utterances in conversation\\nskipping...'.format(min_utts))\n",
    "        return False\n",
    "\n",
    "    speakers = []\n",
    "\n",
    "    for utt in longest_path:\n",
    "        speakers.append(utt.get_speaker().id)\n",
    "    \n",
    "    if len(set(speakers)) > 2:\n",
    "        if print:\n",
    "            print('More than 2 speakers in conversation\\nskipping...')\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Determine number of valid conversations\n",
    "num_valid = 0\n",
    "valid_conv_ids = []  # Will hold IDs of all valid converations\n",
    "for conv in corpus.iter_conversations():\n",
    "    if detect_interlocution(conv, 5):\n",
    "        valid_conv_ids.append(conv.id)\n",
    "        num_valid += 1\n",
    "\n",
    "print('({}/{}) {:.1f}% conversations valid'.format(num_valid, len(corpus.get_conversation_ids()), num_valid*100/len(corpus.get_conversation_ids())))\n"
   ]
  },
  {
   "source": [
    "How to get a single conversation from list of valid IDs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conversation({'obj_type': 'conversation', 'meta': {'page_title': 'Talk:Niger uranium forgeries', 'page_id': 1005730, 'pair_id': '66813686.23567.23567', 'conversation_has_personal_attack': True, 'verified': True, 'pair_verified': True, 'annotation_year': '2018', 'split': 'train'}, 'vectors': [], 'tree': <convokit.model.utteranceNode.UtteranceNode object at 0x0000022E29BF5250>, 'owner': <convokit.model.corpus.Corpus object at 0x0000022DC866C910>, 'id': '68000691.25417.25417'})"
      ]
     },
     "metadata": {},
     "execution_count": 257
    }
   ],
   "source": [
    "corpus.get_conversation(valid_conv_ids[0])"
   ]
  },
  {
   "source": [
    "Now that we have a list of valid conversations, let's find a way to isolate the utterances in a way that we can easily analyze for style accommodation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Mike Garcia', '66.36.136.123']\n['66.36.136.123', '66.36.136.123', 'Mike Garcia', '66.36.136.123', 'Mike Garcia']\n['15832773.3019.3019', '15832773.3035.3019', '15832939.3151.3151', '15833000.3256.3256', '15833036.3275.3275']\n[0, 0, 1, 1, 1]\n{'a': 'Mike Garcia', 'b': '66.36.136.123', 'a_b': [('15832939.3151.3151', '15833000.3256.3256')], 'b_a': [('15832773.3035.3019', '15832939.3151.3151'), ('15833000.3256.3256', '15833036.3275.3275')]}\n"
     ]
    }
   ],
   "source": [
    "def get_speaker_utt_lists(conv):\n",
    "    '''\n",
    "    Generates lists of speaker IDs corresponding to utterances in conv, and gets utterances\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > speakers - list of speakers corresponding to each utterance\n",
    "        > utts - list of utterances from conversation\n",
    "    '''\n",
    "    # Recall, we use the first index longest path in our list of valid conversations\n",
    "    longest_path = conv.get_longest_paths()[0]\n",
    "\n",
    "    speakers = []\n",
    "    utts = []\n",
    "\n",
    "    for utt in longest_path:\n",
    "        utts.append(utt.id)\n",
    "        speakers.append(utt.get_speaker().id)\n",
    "\n",
    "    return speakers, utts\n",
    "\n",
    "def get_pairs(speakers, utts):\n",
    "    '''\n",
    "    Generates a dictionary of pairs of utterances, each pair representing a back and forth interaction\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > speakers - list of speakers corresponding to each utterance\n",
    "        > utts - list of utterances from conversation\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > pairs - dictionary with the following structure\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            a_b : [(tuple of 2 utterance IDs, first being from speaker a and second from speaker b), (...), ...]\n",
    "            b_a : [(tuple of 2 utterance IDs, first being from speaker b and second from speaker a), (...), ...]\n",
    "    '''\n",
    "    # TODO: Account for instances where a speaker speaks multiple times in a row. Combine those into a list of utteranes within the tuples\n",
    "    print(list(set(speakers)))\n",
    "    pairs = {\n",
    "        'a' : list(set(speakers))[0],\n",
    "        'b' : list(set(speakers))[1],\n",
    "        'a_b' : [],\n",
    "        'b_a' : []\n",
    "    }\n",
    "\n",
    "    # We'll say speaker a is the first speaker, and speaker b is the second.False\n",
    "    speaker_shift = [1 if speakers[i] != speakers[i-1] else 0 for i in range(1, len(speakers))]\n",
    "    speaker_shift.insert(0,0) # Prepend 0 (first utterance isn't a response)\n",
    "\n",
    "    for i in range(1, len(speakers)):\n",
    "       if speakers[i] == pairs['b'] and speakers[i-1] == pairs['a']:\n",
    "           pairs['a_b'].append((utts[i-1], utts[i]))\n",
    "       elif speakers[i] == pairs['a'] and speakers[i-1] == pairs['b']:\n",
    "           pairs['b_a'].append((utts[i-1], utts[i]))\n",
    "    print(speakers)\n",
    "    print(utts)\n",
    "    print(speaker_shift)\n",
    "    print(pairs)\n",
    "\n",
    "    return\n",
    "\n",
    "speakers, utts = get_speaker_utt_lists(corpus.get_conversation(valid_conv_ids[3]))\n",
    "get_pairs(speakers, utts)"
   ]
  },
  {
   "source": [
    "To measure style accommodation we have to measure the style markers in each utterance. That's what this following function is for.\n",
    "\n",
    "see https://spacy.io/models/en"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'conjunction, subordinating or preposition'"
      ]
     },
     "metadata": {},
     "execution_count": 363
    }
   ],
   "source": [
    "spacy.explain('IN')"
   ]
  },
  {
   "source": [
    "## spaCy tags\n",
    "\n",
    "\n",
    "| spaCy tag \t| our tag \t| intended definition \t| actual                                   \t|\n",
    "|-----------\t|---------\t|---------------------\t|------------------------------------------\t|\n",
    "| PRP       \t| ppron   \t| personal pronoun    \t| personal pronoun                         \t|\n",
    "|           \t| ipron   \t| impersonal pronoun  \t|                                          \t|\n",
    "|           \t| article \t| article             \t|                                          \t|\n",
    "| CC        \t| conj    \t| conjunction         \t| coordinating conjunction                 \t|\n",
    "| IN        \t| prep    \t| preposition         \t| subordinating or preposition conjunction \t|\n",
    "| MD        \t| auxverb \t| auxiliary verb      \t| modal auxiliary verb                     \t|\n",
    "| RB        \t| adverb  \t| common adverb       \t| adverb                                   \t|\n",
    "|           \t| negate  \t| negation            \t|                                          \t|\n",
    "|           \t| quant   \t| quantifier          \t|                                          \t|\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Utterance(id: '15832773.3035.3019', conversation_id: 15832773.3019.3019, reply-to: 15832773.3019.3019, speaker: Speaker(id: 66.36.136.123, vectors: [], meta: {}), timestamp: 1119740089.0, text: 'Just because Mike Garcia believes this to be true does not mean it should be in the article. I follow SOAD news very carefully and this has never been an issue, let alone being a confirmed fact as Mike Garcia seems to think it is. I would like to see a source or have this deleted. ', vectors: [], meta: {'is_section_header': False, 'comment_has_personal_attack': False, 'toxicity': 0.030666184, 'parsed': [{'rt': 11, 'toks': [{'tok': 'Just', 'tag': 'RB', 'dep': 'advmod', 'up': 4, 'dn': []}, {'tok': 'because', 'tag': 'IN', 'dep': 'mark', 'up': 4, 'dn': []}, {'tok': 'Mike', 'tag': 'NNP', 'dep': 'compound', 'up': 3, 'dn': []}, {'tok': 'Garcia', 'tag': 'NNP', 'dep': 'nsubj', 'up': 4, 'dn': [2]}, {'tok': 'believes', 'tag': 'VBZ', 'dep': 'advcl', 'up': 11, 'dn': [0, 1, 3, 7]}, {'tok': 'this', 'tag': 'DT', 'dep': 'nsubj', 'up': 7, 'dn': []}, {'tok': 'to', 'tag': 'TO', 'dep': 'aux', 'up': 7, 'dn': []}, {'tok': 'be', 'tag': 'VB', 'dep': 'ccomp', 'up': 4, 'dn': [5, 6, 8]}, {'tok': 'true', 'tag': 'JJ', 'dep': 'acomp', 'up': 7, 'dn': []}, {'tok': 'does', 'tag': 'VBZ', 'dep': 'aux', 'up': 11, 'dn': []}, {'tok': 'not', 'tag': 'RB', 'dep': 'neg', 'up': 11, 'dn': []}, {'tok': 'mean', 'tag': 'VB', 'dep': 'ROOT', 'dn': [4, 9, 10, 14, 18]}, {'tok': 'it', 'tag': 'PRP', 'dep': 'nsubj', 'up': 14, 'dn': []}, {'tok': 'should', 'tag': 'MD', 'dep': 'aux', 'up': 14, 'dn': []}, {'tok': 'be', 'tag': 'VB', 'dep': 'ccomp', 'up': 11, 'dn': [12, 13, 15]}, {'tok': 'in', 'tag': 'IN', 'dep': 'prep', 'up': 14, 'dn': [17]}, {'tok': 'the', 'tag': 'DT', 'dep': 'det', 'up': 17, 'dn': []}, {'tok': 'article', 'tag': 'NN', 'dep': 'pobj', 'up': 15, 'dn': [16]}, {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 11, 'dn': []}]}, {'rt': 1, 'toks': [{'tok': 'I', 'tag': 'PRP', 'dep': 'nsubj', 'up': 1, 'dn': []}, {'tok': 'follow', 'tag': 'VBP', 'dep': 'ROOT', 'dn': [0, 3, 5, 6, 10, 14, 28]}, {'tok': 'SOAD', 'tag': 'NNP', 'dep': 'compound', 'up': 3, 'dn': []}, {'tok': 'news', 'tag': 'NN', 'dep': 'dobj', 'up': 1, 'dn': [2]}, {'tok': 'very', 'tag': 'RB', 'dep': 'advmod', 'up': 5, 'dn': []}, {'tok': 'carefully', 'tag': 'RB', 'dep': 'advmod', 'up': 1, 'dn': [4]}, {'tok': 'and', 'tag': 'CC', 'dep': 'cc', 'up': 1, 'dn': []}, {'tok': 'this', 'tag': 'DT', 'dep': 'nsubj', 'up': 10, 'dn': []}, {'tok': 'has', 'tag': 'VBZ', 'dep': 'aux', 'up': 10, 'dn': []}, {'tok': 'never', 'tag': 'RB', 'dep': 'neg', 'up': 10, 'dn': []}, {'tok': 'been', 'tag': 'VBN', 'dep': 'conj', 'up': 1, 'dn': [7, 8, 9, 12, 13]}, {'tok': 'an', 'tag': 'DT', 'dep': 'det', 'up': 12, 'dn': []}, {'tok': 'issue', 'tag': 'NN', 'dep': 'attr', 'up': 10, 'dn': [11]}, {'tok': ',', 'tag': ',', 'dep': 'punct', 'up': 10, 'dn': []}, {'tok': 'let', 'tag': 'VB', 'dep': 'conj', 'up': 1, 'dn': [15, 16]}, {'tok': 'alone', 'tag': 'RB', 'dep': 'advmod', 'up': 14, 'dn': []}, {'tok': 'being', 'tag': 'VBG', 'dep': 'advcl', 'up': 14, 'dn': [19, 23]}, {'tok': 'a', 'tag': 'DT', 'dep': 'det', 'up': 19, 'dn': []}, {'tok': 'confirmed', 'tag': 'VBN', 'dep': 'amod', 'up': 19, 'dn': []}, {'tok': 'fact', 'tag': 'NN', 'dep': 'attr', 'up': 16, 'dn': [17, 18]}, {'tok': 'as', 'tag': 'IN', 'dep': 'mark', 'up': 23, 'dn': []}, {'tok': 'Mike', 'tag': 'NNP', 'dep': 'compound', 'up': 22, 'dn': []}, {'tok': 'Garcia', 'tag': 'NNP', 'dep': 'nsubj', 'up': 23, 'dn': [21]}, {'tok': 'seems', 'tag': 'VBZ', 'dep': 'advcl', 'up': 16, 'dn': [20, 22, 25]}, {'tok': 'to', 'tag': 'TO', 'dep': 'aux', 'up': 25, 'dn': []}, {'tok': 'think', 'tag': 'VB', 'dep': 'xcomp', 'up': 23, 'dn': [24, 27]}, {'tok': 'it', 'tag': 'PRP', 'dep': 'nsubj', 'up': 27, 'dn': []}, {'tok': 'is', 'tag': 'VBZ', 'dep': 'ccomp', 'up': 25, 'dn': [26]}, {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 1, 'dn': []}]}, {'rt': 2, 'toks': [{'tok': 'I', 'tag': 'PRP', 'dep': 'nsubj', 'up': 2, 'dn': []}, {'tok': 'would', 'tag': 'MD', 'dep': 'aux', 'up': 2, 'dn': []}, {'tok': 'like', 'tag': 'VB', 'dep': 'ROOT', 'dn': [0, 1, 4, 11]}, {'tok': 'to', 'tag': 'TO', 'dep': 'aux', 'up': 4, 'dn': []}, {'tok': 'see', 'tag': 'VB', 'dep': 'xcomp', 'up': 2, 'dn': [3, 6, 7, 10]}, {'tok': 'a', 'tag': 'DT', 'dep': 'det', 'up': 6, 'dn': []}, {'tok': 'source', 'tag': 'NN', 'dep': 'dobj', 'up': 4, 'dn': [5]}, {'tok': 'or', 'tag': 'CC', 'dep': 'cc', 'up': 4, 'dn': []}, {'tok': 'have', 'tag': 'VB', 'dep': 'aux', 'up': 10, 'dn': []}, {'tok': 'this', 'tag': 'DT', 'dep': 'nsubj', 'up': 10, 'dn': []}, {'tok': 'deleted', 'tag': 'VBN', 'dep': 'conj', 'up': 4, 'dn': [8, 9]}, {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 2, 'dn': []}]}]})\n"
     ]
    }
   ],
   "source": [
    "def get_style_markers(utt):\n",
    "    '''\n",
    "    Returns a dictionary containing the number of style markers in an utterance\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > utt - a single utterance\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > m - dictionary with the following key value pairs\n",
    "            ppron : # personal pronouns\n",
    "            ipron : # impersonal pronouns\n",
    "            article : # articles\n",
    "            conj : # conjunctions\n",
    "            prep : # prepositions\n",
    "            auxverb : # auxiliary verbs\n",
    "            adverb : # common adverbs\n",
    "            negate : # negations\n",
    "            quant : # quantifiers\n",
    "    '''\n",
    "    print(utt)\n",
    "\n",
    "get_style_markers(corpus.get_utterance(utts[1])) # utts defined in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversation('id': '637809448.22348.22348', 'utterances': ['637809448.22369.22348', '637809448.22348.22348', '637811596.22648.22648', '637812747.23256.23256', '637813419.23856.23856', '637814004.24097.24097', '637814481.24395.24395', '637815918.25399.25399', '637825263.25890.25890', '637842043.26148.26148'], 'meta': {'page_title': 'Talk:Regulation of electronic cigarettes', 'page_id': 42877834, 'pair_id': '639648099.38003.38003', 'conversation_has_personal_attack': False, 'verified': False, 'pair_verified': False, 'annotation_year': '2019', 'split': 'test'})\n['637809448.22348.22348', '637809448.22369.22348', '637811596.22648.22648', '637812747.23256.23256', '637814004.24097.24097', '637814481.24395.24395', '637815918.25399.25399', '637825263.25890.25890', '637842043.26148.26148']\n['QuackGuru', 'QuackGuru', 'AlbinoFerret', 'QuackGuru', 'AlbinoFerret', 'QuackGuru', 'AlbinoFerret', 'QuackGuru', 'AlbinoFerret']\n"
     ]
    }
   ],
   "source": [
    "def populate_dict(conv):\n",
    "    '''\n",
    "    Initializes dictionary with ID information for measure_coordination()\n",
    "    Assumes the conversation will only have two speakers\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > C - dictionary with the following key value pairs\n",
    "            convID : ID of conversation\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "    '''\n",
    "\n",
    "def measure_coordination(conv):\n",
    "    '''\n",
    "    Assumes the converation will only have two speakers\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > C - dictionary with following key value pairs\n",
    "            convID : ID of conversation\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            a_b : asymmetric accomodation from speaker a to speaker b\n",
    "            b_a : asymmetric accomodation from speaker b to speaker a\n",
    "            LSA : symmetric accomodation between bot speakers\n",
    "        > C_m - dictionary with following key value pairs\n",
    "            convID : ID of conversation\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            <m>_a_b : asymmetric accommodation from speaker a to speaker b in style marker m\n",
    "            <m>_b_a : asymmetric accommodation from speaker b to speaker a in style marker m\n",
    "                where <m> can take on the values\n",
    "                    ppron : personal pronouns\n",
    "                    ipron : impersonal pronouns\n",
    "                    article : articles\n",
    "                    conj : conjunctions\n",
    "                    prep : prepositions\n",
    "                    auxverb : auxiliary verbs\n",
    "                    adverb : common adverbs\n",
    "                    negate : negations\n",
    "                    quant : quantifiers\n",
    "\n",
    "    '''\n",
    "    C = populate_dict(conv)\n",
    "    print(conv)\n",
    "    longest_paths = conv.get_longest_paths()\n",
    "    \n",
    "    for path in longest_paths:\n",
    "        print([utt.id for utt in path])\n",
    "        print([utt.get_speaker().id for utt in path])\n",
    "    return\n",
    "\n",
    "conv = corpus.random_conversation()\n",
    "measure_coordination(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}