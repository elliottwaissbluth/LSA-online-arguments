{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd01131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Conversations gone awry, Wikipedia version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at C:\\Users\\ewais\\.convokit\\downloads\\conversations-gone-awry-corpus\n",
      "Downloading conversations-gone-awry-cmv-corpus to C:\\Users\\ewais\\.convokit\\downloads\\conversations-gone-awry-cmv-corpus\n",
      "Downloading conversations-gone-awry-cmv-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-cmv-corpus/full.zip (88.6MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "import spacy\n",
    "import pickle\n",
    "corpus = Corpus(filename=download('conversations-gone-awry-corpus'))\n",
    "reddit_corpus = Corpus(filename=download('conversations-gone-awry-cmv-corpus'))\n",
    "\n",
    "# Load liwc_dic\n",
    "with open('liwc_dic.pkl', 'rb') as handle:\n",
    "    liwc_dic = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 8069\nNumber of Utterances: 30021\nNumber of Conversations: 4188\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MrVoluntarist\n"
     ]
    }
   ],
   "source": [
    "utt = corpus.random_utterance()\n",
    "print(utt.speaker.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversation('id': '835398293.25779.25779', 'utterances': ['835398293.25796.25779', '835398293.25779.25779', '835518978.26448.26448', '835621911.27110.27110', '835683769.28112.28112', '835772989.28498.28498', '835848695.29132.29132'], 'meta': {'page_title': 'Talk:Lady Gaga discography', 'page_id': 20796621, 'pair_id': '798965834.19096.19096', 'conversation_has_personal_attack': True, 'verified': False, 'pair_verified': False, 'annotation_year': '2019', 'split': 'train'})\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3d0c505b5671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mutt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconvo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_utterance_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mutt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "convo = corpus.random_conversation()\n",
    "print(convo)\n",
    "for utt in convo.get_utterance_ids():\n",
    "    print(corpus.get_utterance[utt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['835398293.25779.25779', '835621911.27110.27110', '835683769.28112.28112']\n['DanGaga', 'DanGaga', 'IndianBio']\n[False, False, False]\n['835398293.25779.25779', '835772989.28498.28498', '835848695.29132.29132']\n['DanGaga', 'DanGaga', 'IndianBio']\n[False, False, True]\n['835398293.25779.25779', '835398293.25796.25779', '835518978.26448.26448']\n['DanGaga', 'DanGaga', 'IndianBio']\n[False, False, False]\n"
     ]
    }
   ],
   "source": [
    "paths = convo.get_longest_paths()\n",
    "for path in paths:\n",
    "    print([utt.id for utt in path])\n",
    "    print([utt.get_speaker().id for utt in path])\n",
    "    print([corpus.get_utterance(utt.id).retrieve_meta('comment_has_personal_attack') for utt in path])"
   ]
  },
  {
   "source": [
    "## Utterance features\n",
    "- **id**: index of the utterance\n",
    "- **conversation_id**: id of the first utterance in the converstaion this utterance belongs to\n",
    "- **reply-to**: index of the utterance to which this utterance replies to (None if not a reply)\n",
    "- **speaker**: the speaker who authored the utterance\n",
    "- **timestamp**: timestamp of utterance\n",
    "- **text**: textual content of the utterance\n",
    "- **meta**: metadata for each utterance\n",
    "    - **is_section_header**: whether the utterance is a conversation \"title\" or \"subject\" (if true, the utterance should be ignored)\n",
    "    - **comment_has_personal_attack**: whether this comment was judged by 3 crowdsourced annotators to contain a personal comment_has_personal_attack\n",
    "    - **parsed**: SpaCy parsed version of the utterance text\n",
    "        - **rt**: ??\n",
    "        - **toks**: List of parsed tokens\n",
    "            - **tok**: the token (word, punctuation, etc.)\n",
    "            - **tag**: Detailed part of speech tag\n",
    "            - **dep**: syntactic dependency, i.e. the relation between the tokens\n",
    "            - **up**: list related to dn, not sure how\n",
    "            - **dn**: list related to up, not sure how"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conversation features\n",
    "\n",
    "- **id**: id of the conversation\n",
    "- **utterances**: ids of utterances in the conversation (in order I presume)\n",
    "- **meta**: conversation metadata\n",
    "    - **page_title**: title of page under which conversation is occurring\n",
    "    - **page_id**: unique numerical id of the talk page\n",
    "    - **pair_id**: the id of the conversation that this comment's conversation is paired with\n",
    "    - **conversation_has_personal_attack**: whether any comment in this comment's conversation contains a personal attack\n",
    "    - **verified**: whether the personal attack label has been verified by an internal annotator\n",
    "    - **pair_verified**: whether the personal attack label has been double checked by the internal annotator\n",
    "    - **annotation_year**: self explanatory\n",
    "    - **split**: (train, test, or val) whether this conversation was used as train, test, or val in \"Trouble on the Horizon\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we want to find the conversations that are easy to analyze, i.e. have a structure like (a -> b -> a -> b -> ...). detect_interlocution should reveal those conversations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not enough responses at index 15\n",
      "Not enough responses at index 32\n",
      "Not enough responses at index 94\n",
      "Not enough responses at index 95\n",
      "Not enough responses at index 119\n",
      "Not enough responses at index 155\n",
      "Not enough responses at index 157\n",
      "Not enough responses at index 159\n",
      "Not enough responses at index 164\n",
      "Not enough responses at index 175\n",
      "Not enough responses at index 182\n",
      "Not enough responses at index 186\n",
      "Not enough responses at index 194\n",
      "Not enough responses at index 199\n",
      "Error at index 212, removing\n",
      "Error at index 216, removing\n",
      "Error at index 221, removing\n",
      "Not enough responses at index 226\n",
      "Not enough responses at index 237\n",
      "Not enough responses at index 244\n",
      "Not enough responses at index 247\n",
      "Not enough responses at index 254\n",
      "Not enough responses at index 256\n",
      "Not enough responses at index 259\n",
      "Not enough responses at index 284\n",
      "Not enough responses at index 288\n",
      "Not enough responses at index 289\n",
      "Not enough responses at index 296\n",
      "Not enough responses at index 302\n",
      "Not enough responses at index 333\n",
      "Not enough responses at index 340\n",
      "Not enough responses at index 341\n",
      "Not enough responses at index 366\n",
      "Not enough responses at index 367\n",
      "Not enough responses at index 373\n",
      "Not enough responses at index 400\n",
      "Not enough responses at index 407\n",
      "Not enough responses at index 413\n",
      "Not enough responses at index 415\n",
      "Not enough responses at index 419\n",
      "Not enough responses at index 451\n",
      "Not enough responses at index 457\n",
      "Not enough responses at index 468\n",
      "Not enough responses at index 472\n",
      "Not enough responses at index 476\n",
      "Not enough responses at index 508\n",
      "Not enough responses at index 539\n",
      "Not enough responses at index 548\n",
      "Not enough responses at index 569\n",
      "Not enough responses at index 600\n",
      "Not enough responses at index 611\n",
      "Not enough responses at index 631\n",
      "(582/4188) 13.9% conversations valid\n",
      "Not enough responses at index 765\n",
      "Not enough responses at index 1140\n",
      "Not enough responses at index 1199\n",
      "(1221/6842) 17.8% conversations valid\n"
     ]
    }
   ],
   "source": [
    "# We want to consider conversations with a call-reply structure between two speakers, having at least five utterances\n",
    "def detect_interlocution(conv, min_utts, print=False):\n",
    "    '''\n",
    "    Finds whether the conversation has a call-reply structure between two speakers with at least min_utts utterances\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "        > min_utts - the minimum number of utterances that constitute a valid conversation\n",
    "        > print - whether or not to print why the conversation was rejected\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > bool representing whether or not the conversation's longest path has the aforementioned structure\n",
    "    '''\n",
    "    # At the moment, only considering first longest path if there are multiple # TODO: Add functionality to examine all paths\n",
    "    try:\n",
    "        longest_path = conv.get_longest_paths()[0]\n",
    "    except ValueError as v:\n",
    "        if print:\n",
    "            print(v)\n",
    "            print('skipping...')\n",
    "        return False\n",
    "    \n",
    "    if len(longest_path) < min_utts:\n",
    "        if print:\n",
    "            print('Less than {} utterances in conversation\\nskipping...'.format(min_utts))\n",
    "        return False\n",
    "\n",
    "    speakers = []\n",
    "\n",
    "    for utt in longest_path:\n",
    "        speakers.append(utt.get_speaker().id)\n",
    "    \n",
    "    if len(set(speakers)) > 2:\n",
    "        if print:\n",
    "            print('More than 2 speakers in conversation\\nskipping...')\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def get_valid_conv_ids(corpus, exclude_last=True):\n",
    "    # Determine number of valid conversations\n",
    "    num_valid = 0\n",
    "    valid_conv_ids = []  # Will hold IDs of all valid converations\n",
    "    for conv in corpus.iter_conversations():\n",
    "        if detect_interlocution(conv, 5):\n",
    "            valid_conv_ids.append(conv.id)\n",
    "            num_valid += 1\n",
    "    \n",
    "    # Remove invalid\n",
    "    invalids = []\n",
    "    for j in range(len(valid_conv_ids)):\n",
    "        speakers, utts = get_speaker_utt_lists(corpus.get_conversation(valid_conv_ids[j]))\n",
    "        try:\n",
    "            pairs = get_pairs(speakers, utts)\n",
    "        except:\n",
    "            print('Error at index {}, removing'.format(j))\n",
    "            num_valid -= 1\n",
    "            invalids.append(j)\n",
    "            \n",
    "\n",
    "        # Remove the last utterance which contains the personal attack (or lack thereof)\n",
    "        if exclude_last:\n",
    "            last_utt = utts[-1]\n",
    "            for i in range(len(pairs['a_b'])):\n",
    "                if last_utt in pairs['a_b'][i]:\n",
    "                    del pairs['a_b'][i]\n",
    "                \n",
    "            for i in range(len(pairs['b_a'])):\n",
    "                if last_utt in pairs['b_a'][i]:\n",
    "                    del pairs['b_a'][i]\n",
    "\n",
    "        # Get markers from speaker a to b\n",
    "        # Note the order of a_b switched to b_a here. This is to be consistent with\n",
    "        # the notation of C(b,a) indicating the coordination of b to a\n",
    "        elicit_b_a = initialize_dict()\n",
    "        baseline_b_a = initialize_dict()\n",
    "        for a_b in pairs['a_b']:\n",
    "            u_a  = corpus.get_utterance(a_b[0])\n",
    "            u_b = corpus.get_utterance(a_b[1])\n",
    "            m_u_a = get_style_markers(u_a)\n",
    "            m_u_b = get_style_markers(u_b)\n",
    "            for k in m_u_a:\n",
    "                if m_u_a[k]:\n",
    "                    if m_u_a[k] == m_u_b[k]:  # If b responded to a with same style marker\n",
    "                        elicit_b_a[k] += 1\n",
    "                baseline_b_a[k] += m_u_b[k] # b's response contains m regardless of a's prompt\n",
    "        \n",
    "        # Get markers from speaker b to a\n",
    "        elicit_a_b = initialize_dict()\n",
    "        baseline_a_b = initialize_dict()\n",
    "        for b_a in pairs['b_a']:\n",
    "            u_b  = corpus.get_utterance(b_a[0])\n",
    "            u_a = corpus.get_utterance(b_a[1])\n",
    "            m_u_a = get_style_markers(u_a)\n",
    "            m_u_b = get_style_markers(u_b)\n",
    "            for k in m_u_b:  \n",
    "                if m_u_b[k]:\n",
    "                    if m_u_b[k] == m_u_a[k]:  # If a responded to b with same style marker\n",
    "                        elicit_a_b[k] += 1\n",
    "                baseline_a_b[k] += m_u_a[k] # If a's response contains m regardless of b's prompt\n",
    "        \n",
    "        \n",
    "        # Convert to probabilities, preserving raw baselines for LSM calculation\n",
    "        raw_b_a = baseline_b_a.copy()\n",
    "        raw_a_b = baseline_a_b.copy()\n",
    "        num_response_b_a = len(pairs['a_b'])  # Number of responses from b to a\n",
    "        num_response_a_b = len(pairs['b_a'])  # Number of responses from a to b\n",
    "        # Sometimes there aren't any responses from a to b or from b to a, continue if this is the case\n",
    "        if not num_response_a_b or not num_response_b_a:\n",
    "            print('Not enough responses at index {}'.format(j))\n",
    "            invalids.append(j)\n",
    "            num_valid -= 1\n",
    "\n",
    "    for i, inv in enumerate(invalids):\n",
    "        del valid_conv_ids[inv-i]\n",
    "\n",
    "    print('({}/{}) {:.1f}% conversations valid'.format(num_valid, len(corpus.get_conversation_ids()), num_valid*100/len(corpus.get_conversation_ids())))\n",
    "    return valid_conv_ids\n",
    "\n",
    "\n",
    "valid_conv_ids = get_valid_conv_ids(corpus)\n",
    "r_valid_conv_ids = get_valid_conv_ids(reddit_corpus)"
   ]
  },
  {
   "source": [
    "How to get a single conversation from list of valid IDs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conversation({'obj_type': 'conversation', 'meta': {'page_title': 'User talk:AngryParsley', 'page_id': 1282978, 'pair_id': '12941035.584.584', 'conversation_has_personal_attack': False, 'verified': True, 'pair_verified': True, 'annotation_year': '2018', 'split': 'train'}, 'vectors': [], 'tree': <convokit.model.utteranceNode.UtteranceNode object at 0x000001919C8E8910>, 'owner': <convokit.model.corpus.Corpus object at 0x000001919BF3E970>, 'id': '12451425.436.436'})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "corpus.get_conversation(valid_conv_ids[4])"
   ]
  },
  {
   "source": [
    "Now that we have a list of valid conversations, let's find a way to isolate the utterances in a way that we can easily analyze for style accommodation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': '66.36.136.123',\n",
       " 'b': 'Mike Garcia',\n",
       " 'a_b': [('15832773.3035.3019', '15832939.3151.3151'),\n",
       "  ('15833000.3256.3256', '15833036.3275.3275')],\n",
       " 'b_a': [('15832939.3151.3151', '15833000.3256.3256')]}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def get_speaker_utt_lists(conv):\n",
    "    '''\n",
    "    Generates lists of speaker IDs corresponding to utterances in conv, and gets utterances\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > speakers - list of speakers corresponding to each utterance\n",
    "        > utts - list of utterances from conversation\n",
    "    '''\n",
    "    # Recall, we use the first index longest path in our list of valid conversations\n",
    "    longest_path = conv.get_longest_paths()[0]\n",
    "\n",
    "    speakers = []\n",
    "    utts = []\n",
    "\n",
    "    for utt in longest_path:\n",
    "        utts.append(utt.id)\n",
    "        speakers.append(utt.get_speaker().id)\n",
    "\n",
    "    return speakers, utts\n",
    "\n",
    "def get_pairs(speakers, utts):\n",
    "    '''\n",
    "    Generates a dictionary of pairs of utterances, each pair representing a back and forth interaction\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > speakers - list of speakers corresponding to each utterance\n",
    "        > utts - list of utterances from conversation\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > pairs - dictionary with the following structure\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            a_b : [(tuple of 2 utterance IDs, first being from speaker a and second from speaker b), (...), ...]\n",
    "            b_a : [(tuple of 2 utterance IDs, first being from speaker b and second from speaker a), (...), ...]\n",
    "    '''\n",
    "    # TODO: Account for instances where a speaker speaks multiple times in a row. Combine those into a list of utteranes within the tuples\n",
    "    pairs = {\n",
    "        'a' : list(set(speakers))[0],\n",
    "        'b' : list(set(speakers))[1],\n",
    "        'a_b' : [],\n",
    "        'b_a' : []\n",
    "    }\n",
    "\n",
    "    # We'll say speaker a is the first speaker, and speaker b is the second.False\n",
    "    speaker_shift = [1 if speakers[i] != speakers[i-1] else 0 for i in range(1, len(speakers))]\n",
    "    speaker_shift.insert(0,0) # Prepend 0 (first utterance isn't a response)\n",
    "\n",
    "    for i in range(1, len(speakers)):\n",
    "       if speakers[i] == pairs['b'] and speakers[i-1] == pairs['a']:\n",
    "           pairs['a_b'].append((utts[i-1], utts[i]))\n",
    "       elif speakers[i] == pairs['a'] and speakers[i-1] == pairs['b']:\n",
    "           pairs['b_a'].append((utts[i-1], utts[i]))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "speakers, utts = get_speaker_utt_lists(corpus.get_conversation(valid_conv_ids[3]))\n",
    "get_pairs(speakers, utts)"
   ]
  },
  {
   "source": [
    "To measure style accommodation we have to measure the style markers in each utterance. That's what this following function is for.\n",
    "\n",
    "see https://spacy.io/models/en"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'conjunction, subordinating or preposition'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "spacy.explain('IN')"
   ]
  },
  {
   "source": [
    "## spaCy tags\n",
    "\n",
    "\n",
    "| spaCy tag \t| our tag \t| intended definition \t| actual                                   \t|\n",
    "|-----------\t|---------\t|---------------------\t|------------------------------------------\t|\n",
    "| PRP       \t| ppron   \t| personal pronoun    \t| personal pronoun                         \t|\n",
    "|           \t| ipron   \t| impersonal pronoun  \t|                                          \t|\n",
    "|           \t| article \t| article             \t|                                          \t|\n",
    "| CC        \t| conj    \t| conjunction         \t| coordinating conjunction                 \t|\n",
    "| IN        \t| prep    \t| preposition         \t| subordinating or preposition conjunction \t|\n",
    "| MD        \t| auxverb \t| auxiliary verb      \t| modal auxiliary verb                     \t|\n",
    "| RB        \t| adverb  \t| common adverb       \t| adverb                                   \t|\n",
    "|           \t| negate  \t| negation            \t|                                          \t|\n",
    "|           \t| quant   \t| quantifier          \t|                                          \t|\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'66.36.136.123', 'Mike Garcia'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ppron': 1,\n",
       " 'ipron': 1,\n",
       " 'article': 1,\n",
       " 'conj': 1,\n",
       " 'prep': 1,\n",
       " 'auxverb': 1,\n",
       " 'adverb': 1,\n",
       " 'negate': 0,\n",
       " 'quant': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def get_style_markers(utt):\n",
    "    '''\n",
    "    Returns a dictionary containing the number of style markers in an utterance\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > utt - a single utterance\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > m - dictionary with the following key value pairs\n",
    "            ppron : # personal pronouns\n",
    "            ipron : # impersonal pronouns\n",
    "            article : # articles\n",
    "            conj : # conjunctions\n",
    "            prep : # prepositions\n",
    "            auxverb : # auxiliary verbs\n",
    "            adverb : # common adverbs\n",
    "            negate : # negations\n",
    "            quant : # quantifiers\n",
    "    '''\n",
    "    m = {\n",
    "        'ppron' : 0,\n",
    "        'ipron' : 0,\n",
    "        'article' : 0,\n",
    "        'conj' : 0,\n",
    "        'prep' : 0,\n",
    "        'auxverb' : 0,\n",
    "        'adverb' : 0,\n",
    "        'negate' : 0,\n",
    "        'quant' : 0\n",
    "    }\n",
    "\n",
    "    # Tokenize text\n",
    "    text = utt.text.lower().split()\n",
    "\n",
    "    # Analyze\n",
    "    for word in text:\n",
    "        if word in liwc_dic.keys():\n",
    "            m[liwc_dic[word]] += 1\n",
    "    \n",
    "    # Convert to boolean\n",
    "    for k in m.keys():\n",
    "        if m[k]:\n",
    "            m[k] = 1\n",
    "\n",
    "    return m\n",
    "\n",
    "speakers, utts = get_speaker_utt_lists(corpus.get_conversation(valid_conv_ids[3]))\n",
    "print(set(speakers))\n",
    "get_style_markers(corpus.get_utterance(utts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "convID : 59573834.9091.9091\na : Everyking\nb : Kelly Martin\nnum_response_b_a : 1\nnum_response_a_b : 1\n\n~~ C_b_a ~~\n     ppron : None\n     ipron : None\n     article : 0.00\n     conj : None\n     prep : None\n     auxverb : 0.00\n     adverb : None\n     negate : None\n     quant : None\n\n~~ C_a_b ~~\n     ppron : None\n     ipron : None\n     article : 0.00\n     conj : None\n     prep : None\n     auxverb : 0.00\n     adverb : None\n     negate : None\n     quant : None\n\n~~ LSM ~~\n     ppron : None\n     ipron : None\n     article : 1.00\n     conj : None\n     prep : None\n     auxverb : 1.00\n     adverb : None\n     negate : None\n     quant : None\n\n\nmean_C_b_a : 0.0\nmean_C_a_b : 0.0\nmean_LSM : 1.0\nvalid_markers : ['article', 'auxverb']\ncorpus : wikipedia\npersonal_attack : True\n"
     ]
    }
   ],
   "source": [
    "def initialize_dict():\n",
    "    return {\n",
    "        'ppron' : 0,\n",
    "        'ipron' : 0,\n",
    "        'article' : 0,\n",
    "        'conj' : 0,\n",
    "        'prep' : 0,\n",
    "        'auxverb' : 0,\n",
    "        'adverb' : 0,\n",
    "        'negate' : 0,\n",
    "        'quant' : 0\n",
    "    }\n",
    "\n",
    "def wiki_measure_coordination(conv, corpus, exclude_last, print_output=False):\n",
    "    '''\n",
    "    Assumes the converation will only have two speakers\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "        > print_output - whether to print medial variables\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > C - dictionary with following key value pairs\n",
    "            convID : ID of conversation\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            num_response_b_a : number of responses from b to a\n",
    "            num_response_a_b : number of responses from a to b\n",
    "            C_b_a : dictrionary of asymmetric accomodation from speaker b to speaker a\n",
    "            C_a_b : dictionary of asymmetric accomodation from speaker a to speaker b\n",
    "            LSM : dictionary of symmetric accomodation between both speakers\n",
    "            mean_C_b_a : average accomodation from b towards a across valid markers\n",
    "            mean_C_a_b : average accomodation from a towards b across valid markers\n",
    "            mean_LSM : average of symmetric accommodation\n",
    "            valid_markers : list of valid markers\n",
    "    '''\n",
    "    # ~~~~~~~~~~~ VARIABLES ~~~~~~~~~~~\n",
    "    #     > pairs - dictionary containing interlocution information\n",
    "    #     > raw_b_a - number of style markers used in all responses from b to a\n",
    "    #     > raw_a_b - number of style markers used in all responses from a to b\n",
    "    #     > baseline_b_a - probability of style markers in b's response to a\n",
    "    #     > baseline_a_b - probability of style markers in a's response to b\n",
    "    #     > elicit_b_a - probability of style markers in b's response to a given a exhibited the same marker\n",
    "    #     > elicit_a_b - probability of style markers in a's response to a given b exhibited the same marker\n",
    "    \n",
    "    speakers, utts = get_speaker_utt_lists(conv)\n",
    "    try:\n",
    "        pairs = get_pairs(speakers, utts)\n",
    "    except IndexError as err:\n",
    "        print(speakers)\n",
    "        print(utts)\n",
    "        print(err)\n",
    "        print('Error!')\n",
    "        return None\n",
    "    personal_attack = corpus.get_utterance(utts[-1]).retrieve_meta('comment_has_personal_attack')\n",
    "\n",
    "    # Remove the last utterance which contains the personal attack (or lack thereof)\n",
    "    if exclude_last:\n",
    "        last_utt = utts[-1]\n",
    "        for i in range(len(pairs['a_b'])):\n",
    "            if last_utt in pairs['a_b'][i]:\n",
    "                del pairs['a_b'][i]\n",
    "            \n",
    "        for i in range(len(pairs['b_a'])):\n",
    "            if last_utt in pairs['b_a'][i]:\n",
    "                del pairs['b_a'][i]\n",
    "\n",
    "    # Get markers from speaker a to b\n",
    "    # Note the order of a_b switched to b_a here. This is to be consistent with\n",
    "    # the notation of C(b,a) indicating the coordination of b to a\n",
    "    elicit_b_a = initialize_dict()\n",
    "    baseline_b_a = initialize_dict()\n",
    "    for a_b in pairs['a_b']:\n",
    "        u_a  = corpus.get_utterance(a_b[0])\n",
    "        u_b = corpus.get_utterance(a_b[1])\n",
    "        m_u_a = get_style_markers(u_a)\n",
    "        m_u_b = get_style_markers(u_b)\n",
    "        for k in m_u_a:\n",
    "            if m_u_a[k]:\n",
    "                if m_u_a[k] == m_u_b[k]:  # If b responded to a with same style marker\n",
    "                    elicit_b_a[k] += 1\n",
    "            baseline_b_a[k] += m_u_b[k] # b's response contains m regardless of a's prompt\n",
    "    \n",
    "    # Get markers from speaker b to a\n",
    "    elicit_a_b = initialize_dict()\n",
    "    baseline_a_b = initialize_dict()\n",
    "    for b_a in pairs['b_a']:\n",
    "        u_b  = corpus.get_utterance(b_a[0])\n",
    "        u_a = corpus.get_utterance(b_a[1])\n",
    "        m_u_a = get_style_markers(u_a)\n",
    "        m_u_b = get_style_markers(u_b)\n",
    "        for k in m_u_b:  \n",
    "            if m_u_b[k]:\n",
    "                if m_u_b[k] == m_u_a[k]:  # If a responded to b with same style marker\n",
    "                    elicit_a_b[k] += 1\n",
    "            baseline_a_b[k] += m_u_a[k] # If a's response contains m regardless of b's prompt\n",
    "    \n",
    "    \n",
    "    # Convert to probabilities, preserving raw baselines for LSM calculation\n",
    "    raw_b_a = baseline_b_a.copy()\n",
    "    raw_a_b = baseline_a_b.copy()\n",
    "    num_response_b_a = len(pairs['a_b'])  # Number of responses from b to a\n",
    "    num_response_a_b = len(pairs['b_a'])  # Number of responses from a to b\n",
    "    # Sometimes there aren't any responses from a to b or from b to a, continue if this is the case\n",
    "    if not num_response_a_b or not num_response_b_a:\n",
    "        print('Only one speaker in conversation, skipping')\n",
    "        return None\n",
    "    for k in elicit_a_b.keys():  # Could be any dictionary, they all have the same keys\n",
    "        elicit_b_a[k] = elicit_b_a[k] / num_response_b_a \n",
    "        baseline_b_a[k] = baseline_b_a[k] / num_response_b_a\n",
    "        elicit_a_b[k] = elicit_a_b[k] / num_response_a_b\n",
    "        baseline_a_b[k] = baseline_a_b[k] / num_response_a_b\n",
    "\n",
    "    # Determine asymmetric and symmetric accomodation\n",
    "    C_b_a = initialize_dict() # Accomodation of b towards a\n",
    "    C_a_b = initialize_dict() # Accomodation of a towards b\n",
    "    LSM = initialize_dict()\n",
    "    for k in C_b_a.keys():\n",
    "        if baseline_b_a[k] and baseline_a_b[k]:  # If a and b both exhibited marker m at some point\n",
    "            C_b_a[k] = baseline_b_a[k] - elicit_b_a[k]\n",
    "            C_a_b[k] = baseline_a_b[k] - elicit_a_b[k]\n",
    "            LSM[k] = 1 - abs(raw_a_b[k] - raw_b_a[k]) / (raw_a_b[k] + raw_b_a[k] + 0.0001)\n",
    "        else:                                    # Else, the metric is undefined for marker m\n",
    "            C_b_a[k] = None  # Set to None if there is no data\n",
    "            C_a_b[k] = None\n",
    "            LSM[k] = None\n",
    "\n",
    "    # Get averages across asymmetric measure\n",
    "    valid_markers = []\n",
    "    mean_C_b_a = 0\n",
    "    mean_C_a_b = 0\n",
    "    mean_LSM = 0\n",
    "    for k in C_b_a.keys():\n",
    "        if C_b_a[k] is not None:\n",
    "            mean_C_b_a += C_b_a[k]\n",
    "            mean_C_a_b += C_a_b[k]\n",
    "            mean_LSM += LSM[k]\n",
    "            valid_markers.append(k)\n",
    "    if valid_markers:\n",
    "        mean_C_b_a /= len(valid_markers)\n",
    "        mean_C_a_b /= len(valid_markers)\n",
    "        mean_LSM /= len(valid_markers)\n",
    "\n",
    "    # Construct dictionary to return\n",
    "    C = {\n",
    "        'convID' : conv.id,\n",
    "        'a' : pairs['a'],\n",
    "        'b' : pairs['b'],\n",
    "        'num_response_b_a' : len(pairs['b_a']),\n",
    "        'num_response_a_b' : len(pairs['a_b']),\n",
    "        'C_b_a' : C_b_a,\n",
    "        'C_a_b' : C_a_b,\n",
    "        'LSM' : LSM,\n",
    "        'mean_C_b_a' : mean_C_b_a,\n",
    "        'mean_C_a_b' : mean_C_a_b,\n",
    "        'mean_LSM' : mean_LSM,\n",
    "        'valid_markers' : valid_markers,\n",
    "        'corpus' : 'wikipedia',\n",
    "        'personal_attack' : personal_attack\n",
    "    } \n",
    "\n",
    "    if print_output:\n",
    "        print('pairs: ', pairs)\n",
    "        print('\\nraw_b_a: ', raw_b_a)\n",
    "        print('raw_a_b: ', raw_a_b)\n",
    "        print('\\nelicit_b_a: ', elicit_b_a)\n",
    "        print('elicit_a_b: ', elicit_a_b)\n",
    "        print('\\nbaseline_b_a: ', baseline_b_a)\n",
    "        print('baseline_a_b: ', baseline_a_b)\n",
    "        print('\\nC_b_a: ', C_b_a)\n",
    "        print('C_a_b: ', C_a_b)\n",
    "        print('\\nLSM: ', LSM)\n",
    "        print('\\nmean_C_b_a: ', mean_C_b_a)\n",
    "        print('mean_C_a_b: ', mean_C_a_b)\n",
    "        \n",
    "    return C\n",
    "\n",
    "# for i in range(len(valid_conv_ids)):\n",
    "#     conv = corpus.get_conversation(valid_conv_ids[i])\n",
    "#     C = wiki_measure_coordination(conv, corpus = corpus, exclude_last = True, print_output=False)\n",
    "\n",
    "conv = corpus.get_conversation(valid_conv_ids[10])\n",
    "C = wiki_measure_coordination(conv, corpus = corpus, exclude_last=True, print_output=False)\n",
    "\n",
    "print_coordination(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "True\n",
      "1\n",
      "False\n",
      "2\n",
      "True\n",
      "3\n",
      "False\n",
      "4\n",
      "True\n",
      "5\n",
      "True\n",
      "6\n",
      "True\n",
      "7\n",
      "False\n",
      "8\n",
      "True\n",
      "9\n",
      "False\n",
      "10\n",
      "False\n",
      "11\n",
      "True\n",
      "12\n",
      "True\n",
      "13\n",
      "False\n",
      "14\n",
      "True\n",
      "15\n",
      "False\n",
      "16\n",
      "False\n",
      "17\n",
      "False\n",
      "18\n",
      "False\n",
      "19\n",
      "True\n",
      "20\n",
      "False\n",
      "21\n",
      "True\n",
      "22\n",
      "False\n",
      "23\n",
      "False\n",
      "24\n",
      "True\n",
      "25\n",
      "False\n",
      "26\n",
      "False\n",
      "27\n",
      "True\n",
      "28\n",
      "False\n",
      "29\n",
      "False\n",
      "30\n",
      "False\n",
      "31\n",
      "True\n",
      "32\n",
      "True\n",
      "33\n",
      "False\n",
      "34\n",
      "False\n",
      "35\n",
      "True\n",
      "36\n",
      "False\n",
      "37\n",
      "False\n",
      "38\n",
      "True\n",
      "39\n",
      "False\n",
      "40\n",
      "True\n",
      "41\n",
      "True\n",
      "42\n",
      "False\n",
      "43\n",
      "False\n",
      "44\n",
      "False\n",
      "45\n",
      "False\n",
      "46\n",
      "False\n",
      "47\n",
      "True\n",
      "48\n",
      "False\n",
      "49\n",
      "True\n",
      "50\n",
      "True\n",
      "51\n",
      "False\n",
      "52\n",
      "True\n",
      "53\n",
      "True\n",
      "54\n",
      "False\n",
      "55\n",
      "True\n",
      "56\n",
      "False\n",
      "57\n",
      "True\n",
      "58\n",
      "False\n",
      "59\n",
      "True\n",
      "60\n",
      "True\n",
      "61\n",
      "False\n",
      "62\n",
      "True\n",
      "63\n",
      "True\n",
      "64\n",
      "False\n",
      "65\n",
      "True\n",
      "66\n",
      "False\n",
      "67\n",
      "True\n",
      "68\n",
      "True\n",
      "69\n",
      "False\n",
      "70\n",
      "True\n",
      "71\n",
      "False\n",
      "72\n",
      "True\n",
      "73\n",
      "False\n",
      "74\n",
      "True\n",
      "75\n",
      "False\n",
      "76\n",
      "True\n",
      "77\n",
      "True\n",
      "78\n",
      "True\n",
      "79\n",
      "True\n",
      "80\n",
      "True\n",
      "81\n",
      "False\n",
      "82\n",
      "True\n",
      "83\n",
      "False\n",
      "84\n",
      "True\n",
      "85\n",
      "False\n",
      "86\n",
      "True\n",
      "87\n",
      "False\n",
      "88\n",
      "False\n",
      "89\n",
      "False\n",
      "90\n",
      "True\n",
      "91\n",
      "False\n",
      "92\n",
      "True\n",
      "93\n",
      "True\n",
      "94\n",
      "False\n",
      "95\n",
      "True\n",
      "96\n",
      "True\n",
      "97\n",
      "False\n",
      "98\n",
      "False\n",
      "99\n",
      "False\n",
      "100\n",
      "False\n",
      "101\n",
      "True\n",
      "102\n",
      "False\n",
      "103\n",
      "False\n",
      "104\n",
      "True\n",
      "105\n",
      "False\n",
      "106\n",
      "False\n",
      "107\n",
      "True\n",
      "108\n",
      "False\n",
      "109\n",
      "False\n",
      "110\n",
      "False\n",
      "111\n",
      "True\n",
      "112\n",
      "True\n",
      "113\n",
      "True\n",
      "114\n",
      "True\n",
      "115\n",
      "True\n",
      "116\n",
      "False\n",
      "117\n",
      "True\n",
      "118\n",
      "False\n",
      "119\n",
      "True\n",
      "120\n",
      "True\n",
      "121\n",
      "True\n",
      "122\n",
      "False\n",
      "123\n",
      "True\n",
      "124\n",
      "False\n",
      "125\n",
      "False\n",
      "126\n",
      "False\n",
      "127\n",
      "False\n",
      "128\n",
      "True\n",
      "129\n",
      "True\n",
      "130\n",
      "False\n",
      "131\n",
      "True\n",
      "132\n",
      "False\n",
      "133\n",
      "True\n",
      "134\n",
      "True\n",
      "135\n",
      "True\n",
      "136\n",
      "False\n",
      "137\n",
      "True\n",
      "138\n",
      "False\n",
      "139\n",
      "False\n",
      "140\n",
      "True\n",
      "141\n",
      "True\n",
      "142\n",
      "False\n",
      "143\n",
      "True\n",
      "144\n",
      "True\n",
      "145\n",
      "True\n",
      "146\n",
      "False\n",
      "147\n",
      "True\n",
      "148\n",
      "True\n",
      "149\n",
      "False\n",
      "150\n",
      "True\n",
      "151\n",
      "True\n",
      "152\n",
      "False\n",
      "153\n",
      "False\n",
      "154\n",
      "False\n",
      "155\n",
      "True\n",
      "156\n",
      "False\n",
      "157\n",
      "True\n",
      "158\n",
      "True\n",
      "159\n",
      "False\n",
      "160\n",
      "False\n",
      "161\n",
      "False\n",
      "162\n",
      "False\n",
      "163\n",
      "False\n",
      "164\n",
      "False\n",
      "165\n",
      "True\n",
      "166\n",
      "True\n",
      "167\n",
      "False\n",
      "168\n",
      "True\n",
      "169\n",
      "True\n",
      "170\n",
      "True\n",
      "171\n",
      "True\n",
      "172\n",
      "True\n",
      "173\n",
      "True\n",
      "174\n",
      "True\n",
      "175\n",
      "False\n",
      "176\n",
      "False\n",
      "177\n",
      "True\n",
      "178\n",
      "False\n",
      "179\n",
      "True\n",
      "180\n",
      "False\n",
      "181\n",
      "False\n",
      "182\n",
      "True\n",
      "183\n",
      "True\n",
      "184\n",
      "False\n",
      "185\n",
      "True\n",
      "186\n",
      "True\n",
      "187\n",
      "True\n",
      "188\n",
      "False\n",
      "189\n",
      "False\n",
      "190\n",
      "False\n",
      "191\n",
      "True\n",
      "192\n",
      "False\n",
      "193\n",
      "True\n",
      "194\n",
      "True\n",
      "195\n",
      "False\n",
      "196\n",
      "False\n",
      "197\n",
      "True\n",
      "198\n",
      "False\n",
      "199\n",
      "False\n",
      "200\n",
      "True\n",
      "201\n",
      "True\n",
      "202\n",
      "False\n",
      "203\n",
      "True\n",
      "204\n",
      "True\n",
      "205\n",
      "True\n",
      "206\n",
      "True\n",
      "207\n",
      "True\n",
      "208\n",
      "False\n",
      "209\n",
      "False\n",
      "210\n",
      "False\n",
      "211\n",
      "True\n",
      "212\n",
      "False\n",
      "213\n",
      "True\n",
      "214\n",
      "True\n",
      "215\n",
      "False\n",
      "216\n",
      "False\n",
      "217\n",
      "False\n",
      "218\n",
      "True\n",
      "219\n",
      "True\n",
      "220\n",
      "False\n",
      "221\n",
      "True\n",
      "222\n",
      "False\n",
      "223\n",
      "False\n",
      "224\n",
      "True\n",
      "225\n",
      "True\n",
      "226\n",
      "True\n",
      "227\n",
      "True\n",
      "228\n",
      "True\n",
      "229\n",
      "False\n",
      "230\n",
      "True\n",
      "231\n",
      "False\n",
      "232\n",
      "True\n",
      "233\n",
      "False\n",
      "234\n",
      "True\n",
      "235\n",
      "False\n",
      "236\n",
      "True\n",
      "237\n",
      "True\n",
      "238\n",
      "True\n",
      "239\n",
      "True\n",
      "240\n",
      "False\n",
      "241\n",
      "True\n",
      "242\n",
      "False\n",
      "243\n",
      "False\n",
      "244\n",
      "False\n",
      "245\n",
      "True\n",
      "246\n",
      "True\n",
      "247\n",
      "False\n",
      "248\n",
      "False\n",
      "249\n",
      "False\n",
      "250\n",
      "True\n",
      "251\n",
      "False\n",
      "252\n",
      "True\n",
      "253\n",
      "True\n",
      "254\n",
      "False\n",
      "255\n",
      "False\n",
      "256\n",
      "False\n",
      "257\n",
      "False\n",
      "258\n",
      "True\n",
      "259\n",
      "False\n",
      "260\n",
      "True\n",
      "261\n",
      "False\n",
      "262\n",
      "False\n",
      "263\n",
      "True\n",
      "264\n",
      "False\n",
      "265\n",
      "True\n",
      "266\n",
      "False\n",
      "267\n",
      "True\n",
      "268\n",
      "True\n",
      "269\n",
      "False\n",
      "270\n",
      "True\n",
      "271\n",
      "False\n",
      "272\n",
      "True\n",
      "273\n",
      "False\n",
      "274\n",
      "True\n",
      "275\n",
      "False\n",
      "276\n",
      "False\n",
      "277\n",
      "True\n",
      "278\n",
      "False\n",
      "279\n",
      "False\n",
      "280\n",
      "False\n",
      "281\n",
      "True\n",
      "282\n",
      "False\n",
      "283\n",
      "False\n",
      "284\n",
      "False\n",
      "285\n",
      "True\n",
      "286\n",
      "True\n",
      "287\n",
      "False\n",
      "288\n",
      "False\n",
      "289\n",
      "True\n",
      "290\n",
      "False\n",
      "291\n",
      "False\n",
      "292\n",
      "True\n",
      "293\n",
      "True\n",
      "294\n",
      "False\n",
      "295\n",
      "False\n",
      "296\n",
      "True\n",
      "297\n",
      "True\n",
      "298\n",
      "False\n",
      "299\n",
      "True\n",
      "300\n",
      "False\n",
      "301\n",
      "True\n",
      "302\n",
      "True\n",
      "303\n",
      "True\n",
      "304\n",
      "False\n",
      "305\n",
      "True\n",
      "306\n",
      "True\n",
      "307\n",
      "True\n",
      "308\n",
      "False\n",
      "309\n",
      "True\n",
      "310\n",
      "False\n",
      "311\n",
      "False\n",
      "312\n",
      "True\n",
      "313\n",
      "True\n",
      "314\n",
      "True\n",
      "315\n",
      "True\n",
      "316\n",
      "True\n",
      "317\n",
      "True\n",
      "318\n",
      "False\n",
      "319\n",
      "True\n",
      "320\n",
      "False\n",
      "321\n",
      "True\n",
      "322\n",
      "False\n",
      "323\n",
      "True\n",
      "324\n",
      "False\n",
      "325\n",
      "True\n",
      "326\n",
      "False\n",
      "327\n",
      "True\n",
      "328\n",
      "False\n",
      "329\n",
      "False\n",
      "330\n",
      "True\n",
      "331\n",
      "False\n",
      "332\n",
      "False\n",
      "333\n",
      "False\n",
      "334\n",
      "False\n",
      "335\n",
      "False\n",
      "336\n",
      "True\n",
      "337\n",
      "False\n",
      "338\n",
      "True\n",
      "339\n",
      "False\n",
      "340\n",
      "False\n",
      "341\n",
      "False\n",
      "342\n",
      "True\n",
      "343\n",
      "False\n",
      "344\n",
      "True\n",
      "345\n",
      "False\n",
      "346\n",
      "True\n",
      "347\n",
      "False\n",
      "348\n",
      "True\n",
      "349\n",
      "True\n",
      "350\n",
      "True\n",
      "351\n",
      "False\n",
      "352\n",
      "False\n",
      "353\n",
      "False\n",
      "354\n",
      "True\n",
      "355\n",
      "False\n",
      "356\n",
      "False\n",
      "357\n",
      "True\n",
      "358\n",
      "False\n",
      "359\n",
      "True\n",
      "360\n",
      "False\n",
      "361\n",
      "False\n",
      "362\n",
      "True\n",
      "363\n",
      "False\n",
      "364\n",
      "True\n",
      "365\n",
      "True\n",
      "366\n",
      "False\n",
      "367\n",
      "True\n",
      "368\n",
      "True\n",
      "369\n",
      "False\n",
      "370\n",
      "False\n",
      "371\n",
      "True\n",
      "372\n",
      "True\n",
      "373\n",
      "False\n",
      "374\n",
      "True\n",
      "375\n",
      "True\n",
      "376\n",
      "True\n",
      "377\n",
      "True\n",
      "378\n",
      "False\n",
      "379\n",
      "True\n",
      "380\n",
      "True\n",
      "381\n",
      "True\n",
      "382\n",
      "False\n",
      "383\n",
      "False\n",
      "384\n",
      "False\n",
      "385\n",
      "False\n",
      "386\n",
      "True\n",
      "387\n",
      "True\n",
      "388\n",
      "False\n",
      "389\n",
      "True\n",
      "390\n",
      "False\n",
      "391\n",
      "False\n",
      "392\n",
      "True\n",
      "393\n",
      "True\n",
      "394\n",
      "False\n",
      "395\n",
      "True\n",
      "396\n",
      "False\n",
      "397\n",
      "True\n",
      "398\n",
      "True\n",
      "399\n",
      "True\n",
      "400\n",
      "True\n",
      "401\n",
      "True\n",
      "402\n",
      "False\n",
      "403\n",
      "True\n",
      "404\n",
      "True\n",
      "405\n",
      "False\n",
      "406\n",
      "False\n",
      "407\n",
      "True\n",
      "408\n",
      "False\n",
      "409\n",
      "True\n",
      "410\n",
      "False\n",
      "411\n",
      "True\n",
      "412\n",
      "False\n",
      "413\n",
      "True\n",
      "414\n",
      "False\n",
      "415\n",
      "True\n",
      "416\n",
      "True\n",
      "417\n",
      "False\n",
      "418\n",
      "False\n",
      "419\n",
      "False\n",
      "420\n",
      "False\n",
      "421\n",
      "False\n",
      "422\n",
      "True\n",
      "423\n",
      "False\n",
      "424\n",
      "False\n",
      "425\n",
      "True\n",
      "426\n",
      "False\n",
      "427\n",
      "True\n",
      "428\n",
      "False\n",
      "429\n",
      "False\n",
      "430\n",
      "True\n",
      "431\n",
      "False\n",
      "432\n",
      "False\n",
      "433\n",
      "False\n",
      "434\n",
      "True\n",
      "435\n",
      "True\n",
      "436\n",
      "False\n",
      "437\n",
      "False\n",
      "438\n",
      "True\n",
      "439\n",
      "False\n",
      "440\n",
      "True\n",
      "441\n",
      "True\n",
      "442\n",
      "False\n",
      "443\n",
      "True\n",
      "444\n",
      "False\n",
      "445\n",
      "False\n",
      "446\n",
      "False\n",
      "447\n",
      "False\n",
      "448\n",
      "True\n",
      "449\n",
      "True\n",
      "450\n",
      "True\n",
      "451\n",
      "True\n",
      "452\n",
      "False\n",
      "453\n",
      "True\n",
      "454\n",
      "True\n",
      "455\n",
      "False\n",
      "456\n",
      "True\n",
      "457\n",
      "True\n",
      "458\n",
      "False\n",
      "459\n",
      "True\n",
      "460\n",
      "False\n",
      "461\n",
      "True\n",
      "462\n",
      "False\n",
      "463\n",
      "False\n",
      "464\n",
      "False\n",
      "465\n",
      "False\n",
      "466\n",
      "True\n",
      "467\n",
      "False\n",
      "468\n",
      "False\n",
      "469\n",
      "True\n",
      "470\n",
      "True\n",
      "471\n",
      "False\n",
      "472\n",
      "False\n",
      "473\n",
      "True\n",
      "474\n",
      "False\n",
      "475\n",
      "True\n",
      "476\n",
      "True\n",
      "477\n",
      "True\n",
      "478\n",
      "True\n",
      "479\n",
      "True\n",
      "480\n",
      "False\n",
      "481\n",
      "False\n",
      "482\n",
      "False\n",
      "483\n",
      "False\n",
      "484\n",
      "True\n",
      "485\n",
      "False\n",
      "486\n",
      "True\n",
      "487\n",
      "True\n",
      "488\n",
      "True\n",
      "489\n",
      "False\n",
      "490\n",
      "True\n",
      "491\n",
      "True\n",
      "492\n",
      "False\n",
      "493\n",
      "False\n",
      "494\n",
      "False\n",
      "495\n",
      "True\n",
      "496\n",
      "True\n",
      "497\n",
      "False\n",
      "498\n",
      "True\n",
      "499\n",
      "False\n",
      "500\n",
      "True\n",
      "501\n",
      "False\n",
      "502\n",
      "True\n",
      "503\n",
      "True\n",
      "504\n",
      "False\n",
      "505\n",
      "False\n",
      "506\n",
      "True\n",
      "507\n",
      "False\n",
      "508\n",
      "False\n",
      "509\n",
      "True\n",
      "510\n",
      "False\n",
      "511\n",
      "True\n",
      "512\n",
      "False\n",
      "513\n",
      "True\n",
      "514\n",
      "False\n",
      "515\n",
      "False\n",
      "516\n",
      "True\n",
      "517\n",
      "False\n",
      "518\n",
      "True\n",
      "519\n",
      "False\n",
      "520\n",
      "True\n",
      "521\n",
      "True\n",
      "522\n",
      "False\n",
      "523\n",
      "False\n",
      "524\n",
      "False\n",
      "525\n",
      "False\n",
      "526\n",
      "True\n",
      "527\n",
      "False\n",
      "528\n",
      "False\n",
      "529\n",
      "True\n",
      "530\n",
      "False\n",
      "531\n",
      "True\n",
      "532\n",
      "True\n",
      "533\n",
      "False\n",
      "534\n",
      "True\n",
      "535\n",
      "False\n",
      "536\n",
      "True\n",
      "537\n",
      "True\n",
      "538\n",
      "False\n",
      "539\n",
      "False\n",
      "540\n",
      "True\n",
      "541\n",
      "True\n",
      "542\n",
      "True\n",
      "543\n",
      "False\n",
      "544\n",
      "False\n",
      "545\n",
      "False\n",
      "546\n",
      "False\n",
      "547\n",
      "False\n",
      "548\n",
      "True\n",
      "549\n",
      "True\n",
      "550\n",
      "False\n",
      "551\n",
      "True\n",
      "552\n",
      "False\n",
      "553\n",
      "True\n",
      "554\n",
      "True\n",
      "555\n",
      "False\n",
      "556\n",
      "True\n",
      "557\n",
      "True\n",
      "558\n",
      "False\n",
      "559\n",
      "False\n",
      "560\n",
      "True\n",
      "561\n",
      "True\n",
      "562\n",
      "False\n",
      "563\n",
      "True\n",
      "564\n",
      "False\n",
      "565\n",
      "False\n",
      "566\n",
      "False\n",
      "567\n",
      "True\n",
      "568\n",
      "False\n",
      "569\n",
      "True\n",
      "570\n",
      "False\n",
      "571\n",
      "False\n",
      "572\n",
      "True\n",
      "573\n",
      "False\n",
      "574\n",
      "True\n",
      "575\n",
      "True\n",
      "576\n",
      "False\n",
      "577\n",
      "True\n",
      "578\n",
      "True\n",
      "579\n",
      "True\n",
      "580\n",
      "False\n",
      "581\n",
      "False\n",
      "582\n",
      "False\n",
      "583\n",
      "True\n",
      "584\n",
      "True\n",
      "585\n",
      "True\n",
      "586\n",
      "True\n",
      "587\n",
      "False\n",
      "588\n",
      "False\n",
      "589\n",
      "False\n",
      "590\n",
      "True\n",
      "591\n",
      "True\n",
      "592\n",
      "False\n",
      "593\n",
      "False\n",
      "594\n",
      "False\n",
      "595\n",
      "True\n",
      "596\n",
      "False\n",
      "597\n",
      "False\n",
      "598\n",
      "True\n",
      "599\n",
      "True\n",
      "600\n",
      "True\n",
      "601\n",
      "False\n",
      "602\n",
      "False\n",
      "603\n",
      "False\n",
      "604\n",
      "False\n",
      "605\n",
      "True\n",
      "606\n",
      "True\n",
      "607\n",
      "True\n",
      "608\n",
      "True\n",
      "609\n",
      "False\n",
      "610\n",
      "True\n",
      "611\n",
      "True\n",
      "612\n",
      "True\n",
      "613\n",
      "True\n",
      "614\n",
      "False\n",
      "615\n",
      "False\n",
      "616\n",
      "True\n",
      "617\n",
      "True\n",
      "618\n",
      "True\n",
      "619\n",
      "False\n",
      "620\n",
      "False\n",
      "621\n",
      "True\n",
      "622\n",
      "True\n",
      "623\n",
      "False\n",
      "624\n",
      "True\n",
      "625\n",
      "False\n",
      "626\n",
      "True\n",
      "627\n",
      "False\n",
      "628\n",
      "True\n",
      "629\n",
      "True\n",
      "630\n",
      "True\n",
      "631\n",
      "False\n",
      "632\n",
      "True\n",
      "633\n",
      "False\n",
      "634\n",
      "True\n",
      "635\n",
      "True\n",
      "636\n",
      "False\n",
      "637\n",
      "False\n",
      "638\n",
      "False\n",
      "639\n",
      "False\n",
      "640\n",
      "True\n",
      "641\n",
      "False\n",
      "642\n",
      "False\n",
      "643\n",
      "True\n",
      "644\n",
      "True\n",
      "645\n",
      "True\n",
      "646\n",
      "False\n",
      "647\n",
      "True\n",
      "648\n",
      "False\n",
      "649\n",
      "True\n",
      "650\n",
      "True\n",
      "651\n",
      "False\n",
      "652\n",
      "True\n",
      "653\n",
      "False\n",
      "654\n",
      "False\n",
      "655\n",
      "True\n",
      "656\n",
      "False\n",
      "657\n",
      "False\n",
      "658\n",
      "False\n",
      "659\n",
      "True\n",
      "660\n",
      "False\n",
      "661\n",
      "True\n",
      "662\n",
      "True\n",
      "663\n",
      "False\n",
      "664\n",
      "True\n",
      "665\n",
      "True\n",
      "666\n",
      "False\n",
      "667\n",
      "False\n",
      "668\n",
      "True\n",
      "669\n",
      "False\n",
      "670\n",
      "True\n",
      "671\n",
      "False\n",
      "672\n",
      "False\n",
      "673\n",
      "True\n",
      "674\n",
      "True\n",
      "675\n",
      "True\n",
      "676\n",
      "False\n",
      "677\n",
      "False\n",
      "678\n",
      "True\n",
      "679\n",
      "False\n",
      "680\n",
      "False\n",
      "681\n",
      "False\n",
      "682\n",
      "True\n",
      "683\n",
      "False\n",
      "684\n",
      "False\n",
      "685\n",
      "False\n",
      "686\n",
      "True\n",
      "687\n",
      "True\n",
      "688\n",
      "False\n",
      "689\n",
      "True\n",
      "690\n",
      "True\n",
      "691\n",
      "True\n",
      "692\n",
      "False\n",
      "693\n",
      "True\n",
      "694\n",
      "True\n",
      "695\n",
      "False\n",
      "696\n",
      "True\n",
      "697\n",
      "False\n",
      "698\n",
      "True\n",
      "699\n",
      "False\n",
      "700\n",
      "True\n",
      "701\n",
      "True\n",
      "702\n",
      "True\n",
      "703\n",
      "False\n",
      "704\n",
      "True\n",
      "705\n",
      "True\n",
      "706\n",
      "True\n",
      "707\n",
      "True\n",
      "708\n",
      "True\n",
      "709\n",
      "True\n",
      "710\n",
      "False\n",
      "711\n",
      "True\n",
      "712\n",
      "True\n",
      "713\n",
      "False\n",
      "714\n",
      "True\n",
      "715\n",
      "True\n",
      "716\n",
      "False\n",
      "717\n",
      "True\n",
      "718\n",
      "False\n",
      "719\n",
      "True\n",
      "720\n",
      "True\n",
      "721\n",
      "False\n",
      "722\n",
      "False\n",
      "723\n",
      "False\n",
      "724\n",
      "False\n",
      "725\n",
      "False\n",
      "726\n",
      "True\n",
      "727\n",
      "False\n",
      "728\n",
      "False\n",
      "729\n",
      "True\n",
      "730\n",
      "False\n",
      "731\n",
      "False\n",
      "732\n",
      "False\n",
      "733\n",
      "False\n",
      "734\n",
      "True\n",
      "735\n",
      "False\n",
      "736\n",
      "False\n",
      "737\n",
      "False\n",
      "738\n",
      "True\n",
      "739\n",
      "True\n",
      "740\n",
      "False\n",
      "741\n",
      "False\n",
      "742\n",
      "True\n",
      "743\n",
      "False\n",
      "744\n",
      "True\n",
      "745\n",
      "False\n",
      "746\n",
      "False\n",
      "747\n",
      "True\n",
      "748\n",
      "False\n",
      "749\n",
      "False\n",
      "750\n",
      "True\n",
      "751\n",
      "True\n",
      "752\n",
      "True\n",
      "753\n",
      "False\n",
      "754\n",
      "True\n",
      "755\n",
      "False\n",
      "756\n",
      "False\n",
      "757\n",
      "True\n",
      "758\n",
      "True\n",
      "759\n",
      "False\n",
      "760\n",
      "False\n",
      "761\n",
      "False\n",
      "762\n",
      "True\n",
      "763\n",
      "False\n",
      "764\n",
      "True\n",
      "765\n",
      "True\n",
      "766\n",
      "True\n",
      "767\n",
      "False\n",
      "768\n",
      "True\n",
      "769\n",
      "True\n",
      "770\n",
      "True\n",
      "771\n",
      "False\n",
      "772\n",
      "True\n",
      "773\n",
      "True\n",
      "774\n",
      "False\n",
      "775\n",
      "True\n",
      "776\n",
      "False\n",
      "777\n",
      "True\n",
      "778\n",
      "True\n",
      "779\n",
      "False\n",
      "780\n",
      "True\n",
      "781\n",
      "False\n",
      "782\n",
      "False\n",
      "783\n",
      "False\n",
      "784\n",
      "False\n",
      "785\n",
      "True\n",
      "786\n",
      "True\n",
      "787\n",
      "True\n",
      "788\n",
      "False\n",
      "789\n",
      "False\n",
      "790\n",
      "False\n",
      "791\n",
      "False\n",
      "792\n",
      "True\n",
      "793\n",
      "False\n",
      "794\n",
      "True\n",
      "795\n",
      "True\n",
      "796\n",
      "False\n",
      "797\n",
      "False\n",
      "798\n",
      "False\n",
      "799\n",
      "True\n",
      "800\n",
      "True\n",
      "801\n",
      "False\n",
      "802\n",
      "False\n",
      "803\n",
      "True\n",
      "804\n",
      "False\n",
      "805\n",
      "True\n",
      "806\n",
      "False\n",
      "807\n",
      "True\n",
      "808\n",
      "True\n",
      "809\n",
      "True\n",
      "810\n",
      "True\n",
      "811\n",
      "False\n",
      "812\n",
      "False\n",
      "813\n",
      "True\n",
      "814\n",
      "False\n",
      "815\n",
      "True\n",
      "816\n",
      "False\n",
      "817\n",
      "False\n",
      "818\n",
      "False\n",
      "819\n",
      "True\n",
      "820\n",
      "True\n",
      "821\n",
      "False\n",
      "822\n",
      "True\n",
      "823\n",
      "False\n",
      "824\n",
      "True\n",
      "825\n",
      "False\n",
      "826\n",
      "False\n",
      "827\n",
      "False\n",
      "828\n",
      "True\n",
      "829\n",
      "False\n",
      "830\n",
      "False\n",
      "831\n",
      "False\n",
      "832\n",
      "True\n",
      "833\n",
      "False\n",
      "834\n",
      "False\n",
      "835\n",
      "True\n",
      "836\n",
      "False\n",
      "837\n",
      "False\n",
      "838\n",
      "True\n",
      "839\n",
      "False\n",
      "840\n",
      "True\n",
      "841\n",
      "False\n",
      "842\n",
      "False\n",
      "843\n",
      "True\n",
      "844\n",
      "False\n",
      "845\n",
      "False\n",
      "846\n",
      "True\n",
      "847\n",
      "False\n",
      "848\n",
      "False\n",
      "849\n",
      "True\n",
      "850\n",
      "True\n",
      "851\n",
      "False\n",
      "852\n",
      "False\n",
      "853\n",
      "True\n",
      "854\n",
      "True\n",
      "855\n",
      "True\n",
      "856\n",
      "False\n",
      "857\n",
      "True\n",
      "858\n",
      "True\n",
      "859\n",
      "True\n",
      "860\n",
      "True\n",
      "861\n",
      "True\n",
      "862\n",
      "True\n",
      "863\n",
      "False\n",
      "864\n",
      "True\n",
      "865\n",
      "True\n",
      "866\n",
      "True\n",
      "867\n",
      "False\n",
      "868\n",
      "True\n",
      "869\n",
      "True\n",
      "870\n",
      "True\n",
      "871\n",
      "False\n",
      "872\n",
      "False\n",
      "873\n",
      "True\n",
      "874\n",
      "False\n",
      "875\n",
      "True\n",
      "876\n",
      "False\n",
      "877\n",
      "True\n",
      "878\n",
      "False\n",
      "879\n",
      "True\n",
      "880\n",
      "True\n",
      "881\n",
      "True\n",
      "882\n",
      "True\n",
      "883\n",
      "False\n",
      "884\n",
      "False\n",
      "885\n",
      "False\n",
      "886\n",
      "False\n",
      "887\n",
      "False\n",
      "888\n",
      "True\n",
      "889\n",
      "False\n",
      "890\n",
      "True\n",
      "891\n",
      "False\n",
      "892\n",
      "True\n",
      "893\n",
      "False\n",
      "894\n",
      "False\n",
      "895\n",
      "True\n",
      "896\n",
      "False\n",
      "897\n",
      "False\n",
      "898\n",
      "True\n",
      "899\n",
      "False\n",
      "900\n",
      "False\n",
      "901\n",
      "False\n",
      "902\n",
      "True\n",
      "903\n",
      "True\n",
      "904\n",
      "False\n",
      "905\n",
      "True\n",
      "906\n",
      "True\n",
      "907\n",
      "False\n",
      "908\n",
      "True\n",
      "909\n",
      "False\n",
      "910\n",
      "False\n",
      "911\n",
      "True\n",
      "912\n",
      "False\n",
      "913\n",
      "True\n",
      "914\n",
      "False\n",
      "915\n",
      "True\n",
      "916\n",
      "False\n",
      "917\n",
      "True\n",
      "918\n",
      "True\n",
      "919\n",
      "False\n",
      "920\n",
      "False\n",
      "921\n",
      "False\n",
      "922\n",
      "True\n",
      "923\n",
      "True\n",
      "924\n",
      "True\n",
      "925\n",
      "False\n",
      "926\n",
      "True\n",
      "927\n",
      "False\n",
      "928\n",
      "True\n",
      "929\n",
      "False\n",
      "930\n",
      "False\n",
      "931\n",
      "True\n",
      "932\n",
      "False\n",
      "933\n",
      "True\n",
      "934\n",
      "False\n",
      "935\n",
      "False\n",
      "936\n",
      "True\n",
      "937\n",
      "False\n",
      "938\n",
      "True\n",
      "939\n",
      "False\n",
      "940\n",
      "False\n",
      "941\n",
      "True\n",
      "942\n",
      "False\n",
      "943\n",
      "True\n",
      "944\n",
      "False\n",
      "945\n",
      "False\n",
      "946\n",
      "False\n",
      "947\n",
      "True\n",
      "948\n",
      "False\n",
      "949\n",
      "True\n",
      "950\n",
      "False\n",
      "951\n",
      "False\n",
      "952\n",
      "True\n",
      "953\n",
      "True\n",
      "954\n",
      "True\n",
      "955\n",
      "True\n",
      "956\n",
      "False\n",
      "957\n",
      "False\n",
      "958\n",
      "True\n",
      "959\n",
      "True\n",
      "960\n",
      "True\n",
      "961\n",
      "True\n",
      "962\n",
      "True\n",
      "963\n",
      "False\n",
      "964\n",
      "False\n",
      "965\n",
      "False\n",
      "966\n",
      "False\n",
      "967\n",
      "True\n",
      "968\n",
      "False\n",
      "969\n",
      "True\n",
      "970\n",
      "False\n",
      "971\n",
      "True\n",
      "972\n",
      "True\n",
      "973\n",
      "True\n",
      "974\n",
      "False\n",
      "975\n",
      "False\n",
      "976\n",
      "True\n",
      "977\n",
      "True\n",
      "978\n",
      "False\n",
      "979\n",
      "False\n",
      "980\n",
      "True\n",
      "981\n",
      "False\n",
      "982\n",
      "False\n",
      "983\n",
      "True\n",
      "984\n",
      "True\n",
      "985\n",
      "False\n",
      "986\n",
      "True\n",
      "987\n",
      "False\n",
      "988\n",
      "True\n",
      "989\n",
      "False\n",
      "990\n",
      "True\n",
      "991\n",
      "False\n",
      "992\n",
      "True\n",
      "993\n",
      "False\n",
      "994\n",
      "False\n",
      "995\n",
      "True\n",
      "996\n",
      "False\n",
      "997\n",
      "False\n",
      "998\n",
      "False\n",
      "999\n",
      "True\n",
      "1000\n",
      "False\n",
      "1001\n",
      "False\n",
      "1002\n",
      "True\n",
      "1003\n",
      "True\n",
      "1004\n",
      "True\n",
      "1005\n",
      "False\n",
      "1006\n",
      "True\n",
      "1007\n",
      "True\n",
      "1008\n",
      "False\n",
      "1009\n",
      "True\n",
      "1010\n",
      "False\n",
      "1011\n",
      "True\n",
      "1012\n",
      "True\n",
      "1013\n",
      "False\n",
      "1014\n",
      "False\n",
      "1015\n",
      "False\n",
      "1016\n",
      "True\n",
      "1017\n",
      "False\n",
      "1018\n",
      "True\n",
      "1019\n",
      "True\n",
      "1020\n",
      "False\n",
      "1021\n",
      "True\n",
      "1022\n",
      "True\n",
      "1023\n",
      "False\n",
      "1024\n",
      "True\n",
      "1025\n",
      "True\n",
      "1026\n",
      "False\n",
      "1027\n",
      "True\n",
      "1028\n",
      "False\n",
      "1029\n",
      "True\n",
      "1030\n",
      "False\n",
      "1031\n",
      "True\n",
      "1032\n",
      "False\n",
      "1033\n",
      "False\n",
      "1034\n",
      "True\n",
      "1035\n",
      "False\n",
      "1036\n",
      "True\n",
      "1037\n",
      "False\n",
      "1038\n",
      "True\n",
      "1039\n",
      "False\n",
      "1040\n",
      "False\n",
      "1041\n",
      "True\n",
      "1042\n",
      "True\n",
      "1043\n",
      "True\n",
      "1044\n",
      "False\n",
      "1045\n",
      "True\n",
      "1046\n",
      "False\n",
      "1047\n",
      "False\n",
      "1048\n",
      "True\n",
      "1049\n",
      "True\n",
      "1050\n",
      "True\n",
      "1051\n",
      "False\n",
      "1052\n",
      "False\n",
      "1053\n",
      "False\n",
      "1054\n",
      "False\n",
      "1055\n",
      "False\n",
      "1056\n",
      "True\n",
      "1057\n",
      "True\n",
      "1058\n",
      "True\n",
      "1059\n",
      "True\n",
      "1060\n",
      "False\n",
      "1061\n",
      "False\n",
      "1062\n",
      "False\n",
      "1063\n",
      "False\n",
      "1064\n",
      "False\n",
      "1065\n",
      "True\n",
      "1066\n",
      "True\n",
      "1067\n",
      "False\n",
      "1068\n",
      "False\n",
      "1069\n",
      "True\n",
      "1070\n",
      "False\n",
      "1071\n",
      "True\n",
      "1072\n",
      "False\n",
      "1073\n",
      "False\n",
      "1074\n",
      "True\n",
      "1075\n",
      "False\n",
      "1076\n",
      "True\n",
      "1077\n",
      "True\n",
      "1078\n",
      "False\n",
      "1079\n",
      "False\n",
      "1080\n",
      "True\n",
      "1081\n",
      "False\n",
      "1082\n",
      "False\n",
      "1083\n",
      "False\n",
      "1084\n",
      "False\n",
      "1085\n",
      "False\n",
      "1086\n",
      "True\n",
      "1087\n",
      "True\n",
      "1088\n",
      "False\n",
      "1089\n",
      "True\n",
      "1090\n",
      "False\n",
      "1091\n",
      "True\n",
      "1092\n",
      "True\n",
      "1093\n",
      "False\n",
      "1094\n",
      "True\n",
      "1095\n",
      "True\n",
      "1096\n",
      "False\n",
      "1097\n",
      "True\n",
      "1098\n",
      "True\n",
      "1099\n",
      "False\n",
      "1100\n",
      "False\n",
      "1101\n",
      "True\n",
      "1102\n",
      "False\n",
      "1103\n",
      "False\n",
      "1104\n",
      "True\n",
      "1105\n",
      "True\n",
      "1106\n",
      "False\n",
      "1107\n",
      "False\n",
      "1108\n",
      "False\n",
      "1109\n",
      "True\n",
      "1110\n",
      "False\n",
      "1111\n",
      "False\n",
      "1112\n",
      "True\n",
      "1113\n",
      "False\n",
      "1114\n",
      "True\n",
      "1115\n",
      "False\n",
      "1116\n",
      "False\n",
      "1117\n",
      "True\n",
      "1118\n",
      "False\n",
      "1119\n",
      "True\n",
      "1120\n",
      "True\n",
      "1121\n",
      "True\n",
      "1122\n",
      "False\n",
      "1123\n",
      "True\n",
      "1124\n",
      "True\n",
      "1125\n",
      "True\n",
      "1126\n",
      "False\n",
      "1127\n",
      "True\n",
      "1128\n",
      "False\n",
      "1129\n",
      "False\n",
      "1130\n",
      "False\n",
      "1131\n",
      "True\n",
      "1132\n",
      "False\n",
      "1133\n",
      "False\n",
      "1134\n",
      "False\n",
      "1135\n",
      "True\n",
      "1136\n",
      "False\n",
      "1137\n",
      "True\n",
      "1138\n",
      "False\n",
      "1139\n",
      "False\n",
      "1140\n",
      "True\n",
      "1141\n",
      "False\n",
      "1142\n",
      "True\n",
      "1143\n",
      "False\n",
      "1144\n",
      "False\n",
      "1145\n",
      "True\n",
      "1146\n",
      "True\n",
      "1147\n",
      "False\n",
      "1148\n",
      "True\n",
      "1149\n",
      "True\n",
      "1150\n",
      "True\n",
      "1151\n",
      "True\n",
      "1152\n",
      "True\n",
      "1153\n",
      "False\n",
      "1154\n",
      "True\n",
      "1155\n",
      "True\n",
      "1156\n",
      "False\n",
      "1157\n",
      "True\n",
      "1158\n",
      "False\n",
      "1159\n",
      "False\n",
      "1160\n",
      "False\n",
      "1161\n",
      "True\n",
      "1162\n",
      "False\n",
      "1163\n",
      "True\n",
      "1164\n",
      "False\n",
      "1165\n",
      "True\n",
      "1166\n",
      "True\n",
      "1167\n",
      "False\n",
      "1168\n",
      "True\n",
      "1169\n",
      "True\n",
      "1170\n",
      "False\n",
      "1171\n",
      "True\n",
      "1172\n",
      "False\n",
      "1173\n",
      "True\n",
      "1174\n",
      "True\n",
      "1175\n",
      "False\n",
      "1176\n",
      "True\n",
      "1177\n",
      "False\n",
      "1178\n",
      "True\n",
      "1179\n",
      "False\n",
      "1180\n",
      "True\n",
      "1181\n",
      "False\n",
      "1182\n",
      "True\n",
      "1183\n",
      "False\n",
      "1184\n",
      "False\n",
      "1185\n",
      "False\n",
      "1186\n",
      "False\n",
      "1187\n",
      "True\n",
      "1188\n",
      "False\n",
      "1189\n",
      "False\n",
      "1190\n",
      "True\n",
      "1191\n",
      "True\n",
      "1192\n",
      "False\n",
      "1193\n",
      "False\n",
      "1194\n",
      "True\n",
      "1195\n",
      "True\n",
      "1196\n",
      "True\n",
      "1197\n",
      "False\n",
      "1198\n",
      "Only one speaker in conversation, skipping\n",
      "1199\n",
      "False\n",
      "1200\n",
      "True\n",
      "1201\n",
      "False\n",
      "1202\n",
      "False\n",
      "1203\n",
      "False\n",
      "1204\n",
      "False\n",
      "1205\n",
      "False\n",
      "1206\n",
      "True\n",
      "1207\n",
      "False\n",
      "1208\n",
      "False\n",
      "1209\n",
      "False\n",
      "1210\n",
      "False\n",
      "1211\n",
      "False\n",
      "1212\n",
      "False\n",
      "1213\n",
      "False\n",
      "1214\n",
      "True\n",
      "1215\n",
      "False\n",
      "1216\n",
      "False\n",
      "1217\n",
      "True\n",
      "1218\n",
      "True\n",
      "1219\n",
      "False\n",
      "1220\n",
      "True\n",
      "1221\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def reddit_measure_coordination(conv, corpus, print_output=False):\n",
    "    '''\n",
    "    Assumes the converation will only have two speakers\n",
    "\n",
    "    ~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~\n",
    "        > conv - entire conversation object\n",
    "        > print_output - whether to print medial variables\n",
    "    ~~~~~~~~~~~~ RETURNS ~~~~~~~~~~~~\n",
    "        > C - dictionary with following key value pairs\n",
    "            convID : ID of conversation\n",
    "            a : ID of speaker a\n",
    "            b : ID of speaker b\n",
    "            num_response_b_a : number of responses from b to a\n",
    "            num_response_a_b : number of responses from a to b\n",
    "            C_b_a : dictrionary of asymmetric accomodation from speaker b to speaker a\n",
    "            C_a_b : dictionary of asymmetric accomodation from speaker a to speaker b\n",
    "            LSM : dictionary of symmetric accomodation between both speakers\n",
    "            mean_C_b_a : average accomodation from b towards a across valid markers\n",
    "            mean_C_a_b : average accomodation from a towards b across valid markers\n",
    "            mean_LSM : average of symmetric accommodation\n",
    "            valid_markers : list of valid markers\n",
    "    '''\n",
    "    # ~~~~~~~~~~~ VARIABLES ~~~~~~~~~~~\n",
    "    #     > pairs - dictionary containing interlocution information\n",
    "    #     > raw_b_a - number of style markers used in all responses from b to a\n",
    "    #     > raw_a_b - number of style markers used in all responses from a to b\n",
    "    #     > baseline_b_a - probability of style markers in b's response to a\n",
    "    #     > baseline_a_b - probability of style markers in a's response to b\n",
    "    #     > elicit_b_a - probability of style markers in b's response to a given a exhibited the same marker\n",
    "    #     > elicit_a_b - probability of style markers in a's response to a given b exhibited the same marker\n",
    "    \n",
    "    speakers, utts = get_speaker_utt_lists(conv)\n",
    "    try:\n",
    "        pairs = get_pairs(speakers, utts)\n",
    "    except IndexError as err:\n",
    "        print(speakers)\n",
    "        print(utts)\n",
    "        print(err)\n",
    "        print('Error!')\n",
    "        return None\n",
    "\n",
    "    # Get markers from speaker a to b\n",
    "    # Note the order of a_b switched to b_a here. This is to be consistent with\n",
    "    # the notation of C(b,a) indicating the coordination of b to a\n",
    "    elicit_b_a = initialize_dict()\n",
    "    baseline_b_a = initialize_dict()\n",
    "    for a_b in pairs['a_b']:\n",
    "        u_a  = corpus.get_utterance(a_b[0])\n",
    "        u_b = corpus.get_utterance(a_b[1])\n",
    "        m_u_a = get_style_markers(u_a)\n",
    "        m_u_b = get_style_markers(u_b)\n",
    "        for k in m_u_a:\n",
    "            if m_u_a[k]:\n",
    "                if m_u_a[k] == m_u_b[k]:  # If b responded to a with same style marker\n",
    "                    elicit_b_a[k] += 1\n",
    "            baseline_b_a[k] += m_u_b[k] # b's response contains m regardless of a's prompt\n",
    "    \n",
    "    # Get markers from speaker b to a\n",
    "    elicit_a_b = initialize_dict()\n",
    "    baseline_a_b = initialize_dict()\n",
    "    for b_a in pairs['b_a']:\n",
    "        u_b  = corpus.get_utterance(b_a[0])\n",
    "        u_a = corpus.get_utterance(b_a[1])\n",
    "        m_u_a = get_style_markers(u_a)\n",
    "        m_u_b = get_style_markers(u_b)\n",
    "        for k in m_u_b:  \n",
    "            if m_u_b[k]:\n",
    "                if m_u_b[k] == m_u_a[k]:  # If a responded to b with same style marker\n",
    "                    elicit_a_b[k] += 1\n",
    "            baseline_a_b[k] += m_u_a[k] # If a's response contains m regardless of b's prompt\n",
    "    \n",
    "    \n",
    "    # Convert to probabilities, preserving raw baselines for LSM calculation\n",
    "    raw_b_a = baseline_b_a.copy()\n",
    "    raw_a_b = baseline_a_b.copy()\n",
    "    num_response_b_a = len(pairs['a_b'])  # Number of responses from b to a\n",
    "    num_response_a_b = len(pairs['b_a'])  # Number of responses from a to b\n",
    "    # Sometimes there aren't any responses from a to b or from b to a, continue if this is the case\n",
    "    if not num_response_a_b or not num_response_b_a:\n",
    "        print('Only one speaker in conversation, skipping')\n",
    "        return None\n",
    "    for k in elicit_a_b.keys():  # Could be any dictionary, they all have the same keys\n",
    "        elicit_b_a[k] = elicit_b_a[k] / num_response_b_a \n",
    "        baseline_b_a[k] = baseline_b_a[k] / num_response_b_a\n",
    "        elicit_a_b[k] = elicit_a_b[k] / num_response_a_b\n",
    "        baseline_a_b[k] = baseline_a_b[k] / num_response_a_b\n",
    "\n",
    "    # Determine asymmetric and symmetric accomodation\n",
    "    C_b_a = initialize_dict() # Accomodation of b towards a\n",
    "    C_a_b = initialize_dict() # Accomodation of a towards b\n",
    "    LSM = initialize_dict()\n",
    "    for k in C_b_a.keys():\n",
    "        if baseline_b_a[k] and baseline_a_b[k]:  # If a and b both exhibited marker m at some point\n",
    "            C_b_a[k] = baseline_b_a[k] - elicit_b_a[k]\n",
    "            C_a_b[k] = baseline_a_b[k] - elicit_a_b[k]\n",
    "            LSM[k] = 1 - abs(raw_a_b[k] - raw_b_a[k]) / (raw_a_b[k] + raw_b_a[k] + 0.0001)\n",
    "        else:                                    # Else, the metric is undefined for marker m\n",
    "            C_b_a[k] = None  # Set to None if there is no data\n",
    "            C_a_b[k] = None\n",
    "            LSM[k] = None\n",
    "\n",
    "    # Get averages across asymmetric measure\n",
    "    valid_markers = []\n",
    "    mean_C_b_a = 0\n",
    "    mean_C_a_b = 0\n",
    "    mean_LSM = 0\n",
    "    for k in C_b_a.keys():\n",
    "        if C_b_a[k] is not None:\n",
    "            mean_C_b_a += C_b_a[k]\n",
    "            mean_C_a_b += C_a_b[k]\n",
    "            mean_LSM += LSM[k]\n",
    "            valid_markers.append(k)\n",
    "    if valid_markers:\n",
    "        mean_C_b_a /= len(valid_markers)\n",
    "        mean_C_a_b /= len(valid_markers)\n",
    "        mean_LSM /= len(valid_markers)\n",
    "\n",
    "    # Construct dictionary to return\n",
    "    C = {\n",
    "        'convID' : conv.id,\n",
    "        'a' : pairs['a'],\n",
    "        'b' : pairs['b'],\n",
    "        'num_response_b_a' : len(pairs['b_a']),\n",
    "        'num_response_a_b' : len(pairs['a_b']),\n",
    "        'C_b_a' : C_b_a,\n",
    "        'C_a_b' : C_a_b,\n",
    "        'LSM' : LSM,\n",
    "        'mean_C_b_a' : mean_C_b_a,\n",
    "        'mean_C_a_b' : mean_C_a_b,\n",
    "        'mean_LSM' : mean_LSM,\n",
    "        'valid_markers' : valid_markers,\n",
    "        'corpus' : 'reddit',\n",
    "        'personal_attack' : conv.meta['has_removed_comment']\n",
    "    } \n",
    "    \n",
    "    if print_output:\n",
    "        print('pairs: ', pairs)\n",
    "        print('\\nraw_b_a: ', raw_b_a)\n",
    "        print('raw_a_b: ', raw_a_b)\n",
    "        print('\\nelicit_b_a: ', elicit_b_a)\n",
    "        print('elicit_a_b: ', elicit_a_b)\n",
    "        print('\\nbaseline_b_a: ', baseline_b_a)\n",
    "        print('baseline_a_b: ', baseline_a_b)\n",
    "        print('\\nC_b_a: ', C_b_a)\n",
    "        print('C_a_b: ', C_a_b)\n",
    "        print('\\nLSM: ', LSM)\n",
    "        print('\\nmean_C_b_a: ', mean_C_b_a)\n",
    "        print('mean_C_a_b: ', mean_C_a_b)\n",
    "        \n",
    "    return C\n",
    "\n",
    "for i in range(len(r_valid_conv_ids)):\n",
    "    conv = reddit_corpus.get_conversation(r_valid_conv_ids[i])\n",
    "    C = reddit_measure_coordination(conv, corpus = reddit_corpus, print_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "convID : e8r00ko\na : Buddy5000\nb : dannylandulf\nnum_response_b_a : 3\nnum_response_a_b : 2\n\n~~ C_b_a ~~\n     ppron : 0.00\n     ipron : 0.00\n     article : 0.00\n     conj : 0.50\n     prep : 0.50\n     auxverb : 0.50\n     adverb : 0.00\n     negate : None\n     quant : None\n\n~~ C_a_b ~~\n     ppron : 0.00\n     ipron : 0.33\n     article : 0.00\n     conj : 0.00\n     prep : 0.00\n     auxverb : 0.00\n     adverb : 0.00\n     negate : None\n     quant : None\n\n~~ LSM ~~\n     ppron : 0.80\n     ipron : 0.67\n     article : 0.80\n     conj : 1.00\n     prep : 0.67\n     auxverb : 1.00\n     adverb : 0.80\n     negate : None\n     quant : None\n\n\nmean_C_b_a : 0.21428571428571427\nmean_C_a_b : 0.047619047619047616\nmean_LSM : 0.8190525077964063\nvalid_markers : ['ppron', 'ipron', 'article', 'conj', 'prep', 'auxverb', 'adverb']\ncorpus : reddit\npersonal_attack : False\n"
     ]
    }
   ],
   "source": [
    "def print_coordination(C):\n",
    "    '''\n",
    "    Prints a coordination dictionary (output from measure_coordination) legibly\n",
    "    '''\n",
    "    for k in C.keys():\n",
    "        if isinstance(C[k], dict):\n",
    "            print('\\n~~ {} ~~'.format(k))\n",
    "            for m in C[k].keys():\n",
    "                if C[k][m] is not None:\n",
    "                    print('     {} : {:.2f}'.format(m, C[k][m]))\n",
    "                else:\n",
    "                    print('     {} : None'.format(m))\n",
    "            if k == 'LSM':\n",
    "                print('\\n')\n",
    "        else:\n",
    "            print('{} : {}'.format(k, C[k]))\n",
    "\n",
    "print_coordination(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}